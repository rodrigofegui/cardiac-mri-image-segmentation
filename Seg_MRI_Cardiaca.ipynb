{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Seg_MRI_Cardiaca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HC4K3T4SmEf_",
        "eKFfei90mcAJ",
        "EnCLKLG9og3I",
        "jRA4xxMDuLRG",
        "hcEtyDUbOIcw",
        "UlEma1WCF49k",
        "w7JKL6lA3CmT",
        "MP_30iwQG5Pf",
        "iIDrnFqqI8yY",
        "X4Pej9qVUj_u",
        "hRDKvbFVwLL0",
        "mZjKdfiev5pT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit ('.cardiac': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "67668f413a42110e21fe6b143d2f32782a8af4af415e65683d924b96a65c5efc"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentação de MRI Cardíacas**\n",
        "\n"
      ],
      "metadata": {
        "id": "HC4K3T4SmEf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "eKFfei90mcAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas"
      ],
      "metadata": {
        "id": "z14WjMKNmnIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "\n",
        "!pip install scikit-learn==0.24.2\n",
        "!pip install segmentation-models==1.0.1\n",
        "\n",
        "!pip install nibabel==3.2.1\n",
        "!pip install MedPy==0.4.0\n",
        "\n",
        "!pip install matplotlib\n",
        "\n",
        "!pip install python-decouple==3.4\n",
        "\n",
        "!pip install pydot"
      ],
      "outputs": [],
      "metadata": {
        "id": "NfB9dnKSl-VP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44808246-5671-4c8e-be1a-883a5994d815"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acesso à arquivos"
      ],
      "metadata": {
        "id": "UzHCSwCdnIHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from decouple import Csv, config"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "COLAB_MAIN_PATH = '/content/drive, My Drive/Colab Notebooks/data'"
      ],
      "outputs": [],
      "metadata": {
        "id": "XNB6SCUQxhTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAIN_PATH = config('MAIN_PATH', default=COLAB_MAIN_PATH, cast=Csv())\n",
        "MAIN_PATH"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if config('IN_GOOGLE_COLAB', default=True, cast=bool):\n",
        "    import os, sys\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(MAIN_PATH[0], force_remount=True)\n",
        "    os.chdir('/'.join(MAIN_PATH))\n",
        "    sys.path.append('/'.join(MAIN_PATH))"
      ],
      "outputs": [],
      "metadata": {
        "id": "JQl43uvenSLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137b1377-0e67-4a0f-c8aa-dafc1b704ddb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualização da GPU disponibilizada"
      ],
      "metadata": {
        "id": "9VAnelmOnebU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [],
      "metadata": {
        "id": "0TmRxKiCnnCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ce73c0-59a0-465c-fc14-74e93b4d83d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizando a quantidade de GPUs detectadas"
      ],
      "metadata": {
        "id": "9HRMYmjznryn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f'GPUs available: {len(gpus)}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "kNVZRezpnwlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c1f06c-cbfe-46ea-ccdc-19a0c6af7d4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração de uso gradual e necessário da memória da GPU utilizada"
      ],
      "metadata": {
        "id": "tBDBgymJoECi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for device in gpus:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "    logical_devices = tf.config.list_logical_devices(device_type)\n",
        "    print(f'{len(gpus)} physical vs. {len(logical_devices)} logical')\n",
        "    \n",
        "except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GcgIaH9XoE5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "del gpus\n",
        "del logical_devices"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constantes"
      ],
      "metadata": {
        "id": "EnCLKLG9og3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from os.path import join as join_path"
      ],
      "outputs": [],
      "metadata": {
        "id": "MdsW27iD28sA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SZ = 100"
      ],
      "outputs": [],
      "metadata": {
        "id": "CNe0BZkHokLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RANDOM_SEED = 42"
      ],
      "outputs": [],
      "metadata": {
        "id": "0FRgMFMDo1UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens"
      ],
      "metadata": {
        "id": "2FiWg76aptvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# represent voxels located in the:\n",
        "# 0: background\n",
        "# 1: RV cavity\n",
        "# 2: myocardium\n",
        "# 3: LV cavity \n",
        "CLASSES_CNT = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "teZ1vFnBo86-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INPUT_CHANNELS = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "yhPLtcgFIBS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATCH_STEP = 30"
      ],
      "outputs": [],
      "metadata": {
        "id": "4AJ4EW5HCRpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SUFIX = '_data'"
      ],
      "outputs": [],
      "metadata": {
        "id": "0jmhXzzrjHUd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_SUFIX = '_mask'"
      ],
      "outputs": [],
      "metadata": {
        "id": "388ZVEbVjKoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CLASS_WEIGHT_FILENAME = 'classes_weight.npy'\n",
        "CLASS_WEIGHT_FILENAME = join_path(*MAIN_PATH, CLASS_WEIGHT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PFpk9RQXpLGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RAW_DATA_PRE_PROCESS_SZ = 3"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data-subgroup"
      ],
      "metadata": {
        "id": "OWKzttYtjp7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "6rKj41ofVL5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "XVALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "0-UDTg4lo7GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "fo7dJMWKjNRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DT_SHUFFLE_SZ = 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lwnnmbtnn3_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BASE_DATA_DIR = 'ACDC_2017_dados'\n",
        "\n",
        "RAW_TRAINING_FILENAME = 'training.zip'\n",
        "RAW_TRAINING_DIR = 'raw_train'\n",
        "PATCHES_DIR = f'image_patches_{IMG_SZ}'\n",
        "TRAINING_DIR = 'train'\n",
        "X_VAL_DIR = 'validation'\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "RAW_TRAINING_DIR = join_path(BASE_DATA_DIR, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, X_VAL_DIR)\n",
        "TEST_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TEST_DIR)\n",
        "\n",
        "RAW_TRAINING_FILENAME = join_path(*MAIN_PATH, RAW_TRAINING_FILENAME)\n",
        "RAW_TRAINING_DIR = join_path(*MAIN_PATH, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(*MAIN_PATH, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(*MAIN_PATH, X_VAL_DIR)\n",
        "TEST_DIR = join_path(*MAIN_PATH, TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FypEp4tTqFOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_GLOB_SEARCH = ''.join(['*', IMG_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "VlmtbvhYk-Zh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_GLOB_SEARCH = ''.join(['*', MASK_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPBLY1dCTjwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos"
      ],
      "metadata": {
        "id": "Z5tTzWDkqmFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# MODEL_FILENAME = 'ulas_model'\n",
        "# MODEL_FILENAME = 'ulas_model_v2'\n",
        "# MODEL_FILENAME = 'ulas_model_dice_loss'\n",
        "MODEL_FILENAME = 'ulas_model_dice_loss'"
      ],
      "outputs": [],
      "metadata": {
        "id": "RE7z_CNNqoiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_DIR = join_path(*MAIN_PATH, MODEL_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QW8kwOYwqsS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquitetura Ulas"
      ],
      "metadata": {
        "id": "2lEQdpd8K_la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "POOL_SIZE = 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "nPkeN2YyLCtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas e Funções de perda"
      ],
      "metadata": {
        "id": "M_VUxpZxt5IE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "SMOOTH = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "wpy8ho6IGiTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "FOCAL_LOSS_GAMA = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "d0NCWDkVuDMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento"
      ],
      "metadata": {
        "id": "abjYtJ7zp2Bj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INIT_LEARNING_RATE = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "gPy_ujYcpDiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MIN_LEARNING_RATE = 1e-6"
      ],
      "outputs": [],
      "metadata": {
        "id": "DExT9SdYpNCm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BATCH_SIZE = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "kAAyIdURprUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INITAL_EPOCH = 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "2MGb3tctlHvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAX_EPOCH = 10"
      ],
      "outputs": [],
      "metadata": {
        "id": "cm_NFCiKSIrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAIN_METRIC = 'dice_metric'"
      ],
      "outputs": [],
      "metadata": {
        "id": "R7LBrU0Ptpw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if MODEL_FILENAME == 'unet_plusplus_model':\n",
        "    EVAL_METRIC = f're_lu_{MAIN_METRIC}'\n",
        "else:\n",
        "    EVAL_METRIC = MAIN_METRIC"
      ],
      "outputs": [],
      "metadata": {
        "id": "gIERQ-Kqtt3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "METRIC_THRESHOLD = .5"
      ],
      "outputs": [],
      "metadata": {
        "id": "y1p09qit9-Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "IDXFT87zPDUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_ROTATION = 90"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPQ6ps85PF76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_HOR_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "yPicNXYUPKVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_VER_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "g3hQd0c_PP7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# AUG_WIDTH_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "gwViSbPsPdpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# AUG_HEIGHT_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "UtBEysfLPfoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# AUG_ZOOM_FACTOR = 10\n",
        "# AUG_ZOOM = (10, 16) # x10"
      ],
      "outputs": [],
      "metadata": {
        "id": "qWvTb7owPgaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_FILL_MODE = 'constant'"
      ],
      "outputs": [],
      "metadata": {
        "id": "40y_uDu-PhU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestones do treinamento"
      ],
      "metadata": {
        "id": "A_lgkcSdrq25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "EARLY_STOP_PATIENCE = 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "fp0RTecqsvC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "LR_REDUCER_PATIENCE = 3"
      ],
      "outputs": [],
      "metadata": {
        "id": "__8-O_YPMhMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_FILENAME = join_path(\n",
        "    MODEL_DIR,\n",
        "    f'{MODEL_FILENAME}.h5'\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "asIAvRtHs5Rh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CSV_LOG_FILENAME = join_path(MODEL_DIR, f'{MODEL_FILENAME}_log.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y8OTM6KNs-vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados"
      ],
      "metadata": {
        "id": "MkYM5QDBtPul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_FILENAME = f'{MODEL_FILENAME}_structure.png'\n",
        "PLOT_FILENAME = join_path(MODEL_DIR, PLOT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VAkIzuNPtOzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_WIDTH = 720"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8k9BznKtWcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação das imagens"
      ],
      "metadata": {
        "id": "jRA4xxMDuLRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports desta seção"
      ],
      "metadata": {
        "id": "eLKawJgfvLcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.image import extract_patches"
      ],
      "outputs": [],
      "metadata": {
        "id": "6DctGw4bvN7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens originais, .nii.gz"
      ],
      "metadata": {
        "id": "enXqnOMtiIpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "author: Clément Zotti (clement.zotti@usherbrooke.ca)\n",
        "date: April 2017\n",
        "\n",
        "DESCRIPTION :\n",
        "The script provide helpers functions to handle nifti image format:\n",
        "    - load_nii()\n",
        "    - save_nii()\n",
        "\n",
        "to generate metrics for two images:\n",
        "    - metrics()\n",
        "\n",
        "And it is callable from the command line (see below).\n",
        "Each function provided in this script has comments to understand\n",
        "how they works.\n",
        "\n",
        "HOW-TO:\n",
        "\n",
        "This script was tested for python 3.4.\n",
        "\n",
        "First, you need to install the required packages with\n",
        "    pip install -r requirements.txt\n",
        "\n",
        "After the installation, you have two ways of running this script:\n",
        "    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n",
        "    2) python metrics.py ground_truth/ prediction/\n",
        "\n",
        "The first option will print in the console the dice and volume of each class for the given image.\n",
        "The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n",
        "\n",
        "\n",
        "Based on: http://acdc.creatis.insa-lyon.fr\n",
        "\"\"\"\n",
        "#\n",
        "# Utils function to load and save nifti files with the nibabel package\n",
        "#\n",
        "def load_nii(img_path):\n",
        "    \"\"\"\n",
        "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
        "    everyting needed to save another 'nii' or 'nii.gz'\n",
        "    in the same dimensional space, i.e. the affine matrix and the header\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Three element, the first is a numpy array of the image values,\n",
        "    the second is the affine transformation of the image, and the\n",
        "    last one is the header of the image.\n",
        "    \"\"\"\n",
        "    nimg = nib.load(img_path)\n",
        "    return nimg.get_fdata().astype('float32'), nimg.affine, nimg.header\n",
        "\n",
        "def save_nii(img_path, data, affine, header):\n",
        "    \"\"\"\n",
        "    Function to save a 'nii' or 'nii.gz' file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
        "\n",
        "    data: np.array\n",
        "    Numpy array of the image data.\n",
        "\n",
        "    affine: list of list or np.array\n",
        "    The affine transformation to save with the image.\n",
        "\n",
        "    header: nib.Nifti1Header\n",
        "    The header that define everything about the data\n",
        "    (pleasecheck nibabel documentation).\n",
        "    \"\"\"\n",
        "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
        "    nimg.to_filename(img_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fosux3OuQkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localização dos arquivos"
      ],
      "metadata": {
        "id": "ppq0c2DAimvE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def file_paths(base_dir):\n",
        "    c_paths = {\n",
        "        'config': [],\n",
        "        'ground_truth': [],\n",
        "        'images': [],\n",
        "        '4d': []\n",
        "    }\n",
        "\n",
        "    for c_dir, next_dirs, file_names in os.walk(base_dir):\n",
        "        # skip root\n",
        "        if next_dirs:\n",
        "            continue\n",
        "\n",
        "        c_patient = os.path.basename(c_dir)\n",
        "\n",
        "        for f_n in file_names:\n",
        "            f_n = os.path.join(c_dir, f_n)\n",
        "\n",
        "            if f_n.endswith('.cfg'): file_type = 'config'\n",
        "            elif '_gt' in f_n: file_type = 'ground_truth'\n",
        "            elif '_4d' in f_n: file_type = '4d'\n",
        "            else: file_type = 'images'\n",
        "\n",
        "            c_paths[file_type].append(f_n)\n",
        "\n",
        "    for file_type in c_paths.keys():\n",
        "        c_paths[file_type].sort()\n",
        "\n",
        "    return c_paths"
      ],
      "outputs": [],
      "metadata": {
        "id": "XLJTixvmiP5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversões diretas salvas"
      ],
      "metadata": {
        "id": "3XN_in9viXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_data(file_paths, is_training=True, initial=0, look_up_sz=0):\n",
        "    images_filename = os.path.join(*MAIN_PATH, f'{\"training\" if is_training else \"test\"}_data.npy')\n",
        "    gt_filename = os.path.join(*MAIN_PATH, f'{\"training\" if is_training else \"test\"}_gt_data.npy')\n",
        "\n",
        "    try:\n",
        "        imgs = np.load(images_filename, allow_pickle=True)\n",
        "        imgs_gt = np.load(gt_filename, allow_pickle=True)\n",
        "\n",
        "        if np.any(imgs) and np.any(imgs_gt):\n",
        "            print('carregado dos arquivos')\n",
        "\n",
        "            return tf.convert_to_tensor(imgs), tf.convert_to_tensor(imgs_gt, dtype=tf.float32)\n",
        "    except:\n",
        "        print('lendo imagens arquivos')\n",
        "        imgs, imgs_gt =  _load_data(file_paths, initial, look_up_sz)\n",
        "\n",
        "        # np.save(images_filename, imgs)\n",
        "        # np.save(gt_filename, imgs_gt)\n",
        "\n",
        "        return imgs, imgs_gt\n",
        "\n",
        "def load_classes_weight(labels=None):\n",
        "    return None\n",
        "    try:\n",
        "        weights = np.load(CLASS_WEIGHT_FILENAME, allow_pickle=True)\n",
        "\n",
        "        if np.any(weights):\n",
        "            print('carregado do arquivo')\n",
        "\n",
        "            return weights\n",
        "    except:\n",
        "        print('calculando pesos')\n",
        "        if not np.any(labels):\n",
        "            return None\n",
        "\n",
        "        weights = compute_class_weight(\n",
        "            'balanced',\n",
        "            np.arange(CLASSES_CNT),\n",
        "            tf.reshape(tf.cast(labels, tf.int8), [-1]).numpy()\n",
        "        )\n",
        "\n",
        "        np.save(CLASS_WEIGHT_FILENAME, weights)\n",
        "\n",
        "        return weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZfLGFpW2iV19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento das imagens originais"
      ],
      "metadata": {
        "id": "gEiOw6_JitX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_data(file_paths, initial=0, look_up_sz=0):\n",
        "    images, ground_truth = tf.convert_to_tensor([]), tf.convert_to_tensor([])\n",
        "    cnt = initial\n",
        "    \n",
        "    final_idx = min(initial + look_up_sz, len(file_paths['images']))\n",
        "\n",
        "    raw_images = file_paths['images'][initial: final_idx]\n",
        "    raw_ground_truth = file_paths['ground_truth'][initial: final_idx]\n",
        "\n",
        "    for c_img, c_ground_truth in zip(raw_images, raw_ground_truth):\n",
        "        print(f'processing {cnt}...')\n",
        "\n",
        "        # we load 3D training image\n",
        "        training_image, _, _ = load_nii(c_img)\n",
        "        # we load 3D training mask (shape=(512,512,129))\n",
        "        train_ground_truth, _, _ = load_nii(c_ground_truth)\n",
        "\n",
        "        for k in range(min(train_ground_truth.shape[-1], training_image.shape[-1])):\n",
        "            #axial cuts are made along the z axis with undersampling\n",
        "            gt_2d = np.array(train_ground_truth[::, ::, k])\n",
        "\n",
        "            # invalid ground truth\n",
        "            if len(np.unique(gt_2d)) == 1:\n",
        "                continue\n",
        "\n",
        "            image_patches = _extract_patches(\n",
        "                _pre_process_img(np.array(training_image[::, ::, k]))\n",
        "            )\n",
        "            gt_patches = _extract_patches(gt_2d)\n",
        "\n",
        "            if (tf.size(images) == 0).numpy():\n",
        "                images = image_patches\n",
        "            else:\n",
        "                images = tf.concat((images, image_patches), axis=0)\n",
        "\n",
        "            if (tf.size(ground_truth) == 0).numpy():\n",
        "                ground_truth = gt_patches\n",
        "            else:\n",
        "                ground_truth = tf.concat((ground_truth, gt_patches), axis=0)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "    ground_truth = tf.cast(ground_truth, tf.int8)\n",
        "\n",
        "    return images, ground_truth\n",
        "\n",
        "def _extract_patches(image_2d):\n",
        "    image_2d = tf.expand_dims(tf.expand_dims(image_2d, axis=-1), axis=0)\n",
        "\n",
        "    if image_2d.shape[1] < IMG_SZ or image_2d.shape[2] < IMG_SZ:\n",
        "        return tf.image.resize(\n",
        "            image_2d, (IMG_SZ, IMG_SZ), method='nearest'\n",
        "        )\n",
        "\n",
        "    image_patches = extract_patches(\n",
        "        image_2d,\n",
        "        sizes=[1, IMG_SZ, IMG_SZ, 1],\n",
        "        strides=[1, PATCH_STEP, PATCH_STEP, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    return tf.reshape(\n",
        "        image_patches,\n",
        "        [image_patches.shape[1] * image_patches.shape[2], IMG_SZ, IMG_SZ, 1]\n",
        "    )\n",
        "\n",
        "# Based on: https://github.com/MinaJf/FU-net/blob/HEAD/image_loder.py\n",
        "def _pre_process_img(img):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # standardization (zero mean)\n",
        "    img -= tf.math.reduce_mean(img)\n",
        "    img /= tf.math.reduce_std(img)\n",
        "\n",
        "    # normalize between [0, 1]\n",
        "    img -= tf.math.reduce_min(img)\n",
        "    img /= tf.math.reduce_max(img)\n",
        "\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "7rDOEKiCvsVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_patches(patches, base_dir, is_label=False, initial=1):\n",
        "    for ind, img in enumerate(patches, start=initial):\n",
        "        img_name = f'{ind}{MASK_SUFIX if is_label else IMG_SUFIX}'\n",
        "        img_path = os.path.join(base_dir, img_name)\n",
        "\n",
        "        np.save(img_path, img)\n",
        "\n",
        "        print(f'saved <{patches.dtype}> {img_path}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y4fDYPWhh_4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def create_data():\n",
        "    training_paths = file_paths(RAW_TRAINING_DIR)\n",
        "\n",
        "    train_patch_cnt, xval_patch_cnt, test_patch_cnt = 1, 1, 1\n",
        "\n",
        "    for ind in range(0, len(training_paths['images']), RAW_DATA_PRE_PROCESS_SZ):\n",
        "        raw_train_data, raw_train_labels = load_data(training_paths, initial=ind, look_up_sz=RAW_DATA_PRE_PROCESS_SZ)\n",
        "\n",
        "        print(f'raw_train_data: {raw_train_data.shape}\\n\\t{raw_train_data.dtype}')\n",
        "        print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')\n",
        "\n",
        "        train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "            raw_train_data.numpy(), raw_train_labels.numpy(),\n",
        "            test_size=VALIDATION_PROPORTION,\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "        train_data, xval_data, train_labels, xval_labels = train_test_split(\n",
        "            train_data, train_labels,\n",
        "            test_size=XVALIDATION_PROPORTION,\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "\n",
        "        print(f'train_data: {train_data.shape} - {train_data.dtype}')\n",
        "        print(f'train_labels: {train_labels.shape} - {train_labels.dtype}')\n",
        "        \n",
        "        print(f'xval_data: {xval_data.shape} - {xval_data.dtype}')\n",
        "        print(f'xval_labels: {xval_labels.shape} - {xval_labels.dtype}')\n",
        "\n",
        "        print(f'test_data: {test_data.shape} - {test_data.dtype}')\n",
        "        print(f'test_labels: {test_labels.shape} - {test_labels.dtype}')\n",
        "\n",
        "        save_patches(train_labels, TRAINING_DIR, is_label=True, initial=train_patch_cnt)\n",
        "        save_patches(train_data, TRAINING_DIR, initial=train_patch_cnt)\n",
        "\n",
        "        save_patches(xval_labels, X_VAL_DIR, is_label=True, initial=xval_patch_cnt)\n",
        "        save_patches(xval_data, X_VAL_DIR, initial=xval_patch_cnt)\n",
        "\n",
        "        save_patches(test_labels, TEST_DIR, is_label=True, initial=test_patch_cnt)\n",
        "        save_patches(test_data, TEST_DIR, initial=test_patch_cnt)\n",
        "\n",
        "        train_patch_cnt += len(train_data)\n",
        "        xval_patch_cnt += len(xval_data)\n",
        "        test_patch_cnt += len(test_data)\n",
        "\n",
        "        del train_data\n",
        "        del train_labels\n",
        "\n",
        "        del xval_data\n",
        "        del xval_labels\n",
        "        \n",
        "        del test_data\n",
        "        del test_labels\n",
        "        \n",
        "    del training_paths\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação dos dados"
      ],
      "metadata": {
        "id": "Al2EYzA3kFup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.data import Dataset\n",
        "from numpy import load\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import skimage.transform as img_transform\n",
        "from gc import collect as gc_collector\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "vyBVdSOHkKfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def keras_model_memory_usage_in_bytes(model, *, batch_size: int):\n",
        "#     \"\"\"\n",
        "#     Return the estimated memory usage of a given Keras model in bytes.\n",
        "#     This includes the model weights and layers, but excludes the dataset.\n",
        "\n",
        "#     The model shapes are multipled by the batch size, but the weights are not.\n",
        "\n",
        "#     Args:\n",
        "#         model: A Keras model.\n",
        "#         batch_size: The batch size you intend to run the model with. If you\n",
        "#             have already specified the batch size in the model itself, then\n",
        "#             pass `1` as the argument here.\n",
        "#     Returns:\n",
        "#         An estimate of the Keras model's memory usage in bytes.\n",
        "\n",
        "#     \"\"\"\n",
        "#     default_dtype = tf.keras.backend.floatx()\n",
        "#     shapes_mem_count = 0\n",
        "#     internal_model_mem_count = 0\n",
        "#     for layer in model.layers:\n",
        "#         if isinstance(layer, tf.keras.Model):\n",
        "#             internal_model_mem_count += keras_model_memory_usage_in_bytes(\n",
        "#                 layer, batch_size=batch_size\n",
        "#             )\n",
        "#         single_layer_mem = tf.as_dtype(layer.dtype or default_dtype).size\n",
        "#         out_shape = layer.output_shape\n",
        "#         if isinstance(out_shape, list):\n",
        "#             out_shape = out_shape[0]\n",
        "#         for s in out_shape:\n",
        "#             if s is None:\n",
        "#                 continue\n",
        "#             single_layer_mem *= s\n",
        "#         shapes_mem_count += single_layer_mem\n",
        "\n",
        "#     trainable_count = sum(\n",
        "#         [tf.keras.backend.count_params(p) for p in model.trainable_weights]\n",
        "#     )\n",
        "#     non_trainable_count = sum(\n",
        "#         [tf.keras.backend.count_params(p) for p in model.non_trainable_weights]\n",
        "#     )\n",
        "\n",
        "#     total_memory = (\n",
        "#         batch_size * shapes_mem_count\n",
        "#         + internal_model_mem_count\n",
        "#         + trainable_count\n",
        "#         + non_trainable_count\n",
        "#     )\n",
        "#     return total_memory"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def get_model_memory_usage(batch_size, model):\n",
        "#     shapes_mem_count = 0\n",
        "#     internal_model_mem_count = 0\n",
        "#     for l in model.layers:\n",
        "#         layer_type = l.__class__.__name__\n",
        "#         if layer_type == 'Model':\n",
        "#             internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
        "#         single_layer_mem = 1\n",
        "#         out_shape = l.output_shape\n",
        "#         if type(out_shape) is list:\n",
        "#             out_shape = out_shape[0]\n",
        "#         for s in out_shape:\n",
        "#             if s is None:\n",
        "#                 continue\n",
        "#             single_layer_mem *= s\n",
        "#         shapes_mem_count += single_layer_mem\n",
        "\n",
        "#     trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
        "#     non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
        "\n",
        "#     print(K.floatx())\n",
        "#     number_size = 4.0\n",
        "#     if K.floatx() == 'float16':\n",
        "#         number_size = 2.0\n",
        "#     if K.floatx() == 'float64':\n",
        "#         number_size = 8.0\n",
        "\n",
        "#     total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
        "#     gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
        "#     return gbytes"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def check_cnt(main_path):\n",
        "    img_filenames = glob(os.path.join(main_path, IMG_GLOB_SEARCH))\n",
        "    mask_filenames = glob(os.path.join(main_path, MASK_GLOB_SEARCH))\n",
        "\n",
        "    img_cnt = len(img_filenames)\n",
        "    mask_cnt = len(mask_filenames)\n",
        "\n",
        "    print('img_cnt', img_cnt)\n",
        "    print('mask_cnt', mask_cnt)\n",
        "\n",
        "    return (\n",
        "        img_cnt if img_cnt == mask_cnt else 0,\n",
        "        tf.convert_to_tensor(img_filenames),\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "0JpDzETkm9wQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_images(batch_paths):\n",
        "    def _load_img(img_path):\n",
        "        img_path = img_path.decode()\n",
        "\n",
        "        image = load(img_path, allow_pickle=True)\n",
        "        mask_path = img_path.replace(IMG_SUFIX, MASK_SUFIX)\n",
        "        \n",
        "        mask = load(mask_path, allow_pickle=True)\n",
        "\n",
        "        mask = mask.astype('int8')\n",
        "      \n",
        "        return image, mask\n",
        "\n",
        "    return _load_img(batch_paths)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6uHK3-WqkNMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def ensure_shape(img_batch, mask_batch):\n",
        "    img_batch = tf.convert_to_tensor(img_batch)\n",
        "    mask_batch = tf.convert_to_tensor(mask_batch)\n",
        "\n",
        "    # img_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "    # mask_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "\n",
        "    img_batch.set_shape((IMG_SZ, IMG_SZ, 1))\n",
        "    mask_batch.set_shape((IMG_SZ, IMG_SZ, 1))\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "sLLRl-FPkZal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def pre_processing(img_batch, mask_batch):\n",
        "    mask_batch = tf.cast(mask_batch, 'uint8')\n",
        "    # if not mask_batch.shape:\n",
        "    #     mask_batch.set_shape(img_batch.shape)\n",
        "\n",
        "    mask_batch = tf.one_hot(mask_batch, CLASSES_CNT)\n",
        "    mask_batch = tf.squeeze(mask_batch)\n",
        "    # mask_batch = tf.squeeze(mask_batch, axis=3)\n",
        "    \n",
        "    mask_batch = tf.cast(mask_batch, 'int8')\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "XZIfFEoArrIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _augmentation(combined_batches):\n",
        "    c_img, c_mask = combined_batches\n",
        "\n",
        "    # horizontal_flip=True,\n",
        "    if AUG_W_HOR_FLIP and tf.random.uniform([]) < .5:\n",
        "        c_img = tf.image.flip_left_right(c_img)\n",
        "        c_mask = tf.image.flip_left_right(c_mask)\n",
        "\n",
        "    # vertical_flip=True,\n",
        "    if AUG_W_VER_FLIP and tf.random.uniform([]) < .5:\n",
        "        c_img = tf.image.flip_up_down(c_img)\n",
        "        c_mask = tf.image.flip_up_down(c_mask)\n",
        "\n",
        "    # rotation_range=90\n",
        "    if tf.random.uniform([]) < .5:\n",
        "        angle = tf.random.uniform([], -AUG_ROTATION // 2, AUG_ROTATION // 2, dtype=tf.int32).numpy()\n",
        "\n",
        "        c_img = img_transform.rotate(np.array(c_img), angle, mode=AUG_FILL_MODE)\n",
        "        c_mask = img_transform.rotate(np.array(c_mask), angle, mode=AUG_FILL_MODE)\n",
        "\n",
        "    # zoom_range=AUG_ZOOM\n",
        "    # width_shift_range=.4\n",
        "    # height_shift_range=.4\n",
        "    \n",
        "    return tf.convert_to_tensor(c_img), tf.convert_to_tensor(c_mask, dtype='int8')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def data_augmentation(img_batch, mask_batch):\n",
        "    gc_collector()\n",
        "\n",
        "    return _augmentation((img_batch, mask_batch))"
      ],
      "outputs": [],
      "metadata": {
        "id": "7SIIEIy301ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def final_cast(img_batch, mask_batch):\n",
        "    mask_batch = tf.cast(mask_batch, 'float32')\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_dataset(main_path, shuffle_sz=False, should_data_aug=False):\n",
        "    dataset = Dataset.list_files(os.path.join(main_path, IMG_GLOB_SEARCH), shuffle=True, seed=RANDOM_SEED)\n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "    if shuffle_sz:\n",
        "        dataset = dataset.shuffle(\n",
        "            buffer_size=shuffle_sz,\n",
        "            reshuffle_each_iteration=True\n",
        "        )\n",
        "\n",
        "    dataset = dataset.map(\n",
        "        lambda img_path: tf.numpy_function(_load_images, [img_path], (tf.float32, tf.int8)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    dataset = dataset.map(ensure_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.map(pre_processing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if should_data_aug:\n",
        "        dataset = dataset.map(\n",
        "            # data_augmentation,\n",
        "            lambda img, mask: tf.numpy_function(data_augmentation, [img, mask], (tf.float32, tf.int8)),\n",
        "            num_parallel_calls=tf.data.AUTOTUNE\n",
        "        )\n",
        "\n",
        "    dataset = dataset.map(final_cast, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "    dataset = dataset.prefetch(buffer_size=1)\n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "DI6iSPxOkcdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def display_sample(display_list, to_save=False):\n",
        "    \"\"\"Show side-by-side an input image,\n",
        "    the ground truth and the prediction.\n",
        "    \"\"\"\n",
        "    plt.figure(dpi=180)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    if len(display_list) == 3:\n",
        "        gt = display_list[1]\n",
        "        pred = display_list[2]\n",
        "\n",
        "        # gt = tf.image.resize(gt, (50, 50), 'nearest')\n",
        "        # pred = tf.image.resize(pred, (50, 50), 'nearest')\n",
        "        \n",
        "        equal = gt * pred\n",
        "        \n",
        "        display_list.append(equal)\n",
        "        display_list.append(gt - equal)\n",
        "        display_list.append(pred - equal)\n",
        "\n",
        "    settings = [\n",
        "        { # 0\n",
        "            'title': 'Input Image',\n",
        "            'pre_processing': lambda x: tf.squeeze(x, axis=2),\n",
        "        },\n",
        "        { # 1\n",
        "            'title': 'Ground Truth',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 2\n",
        "            'title': 'Prediction',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 3\n",
        "            'title': 'Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 4\n",
        "            'title': 'G.T. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 5\n",
        "            'title': 'Pred. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    for ind, image in enumerate(display_list):\n",
        "        print()\n",
        "        print(image.shape)\n",
        "        plt.subplot(1, len(display_list), ind + 1)\n",
        "        plt.title(settings[ind]['title'])\n",
        "        plt.imshow(settings[ind]['pre_processing'](image), cmap='hot')\n",
        "        plt.axis('off')\n",
        "\n",
        "    if to_save and len(display_list) == len(settings):\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.svg'), dpi=300)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.png'), dpi=300)\n",
        "\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nOYPJSVWwGnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo em mémoria"
      ],
      "metadata": {
        "id": "hcEtyDUbOIcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "m_mBzEfeOOaj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZFteRO3KOQfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Based on: https://github.com/mjbhobe/dl-tensorflow-keras/blob/master/kr_helper_funcs.py\n",
        "def save_model(model, file_name, save_dir):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"\n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(f'Não foi possível criar o repositório \"{save_dir}\", para salvar o modelo. Terminando a execução!')\n",
        "            raise err\n",
        "\n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (file_name + '.h5'))\n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save(\n",
        "        h5_file_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "        save_traces=True,\n",
        "    )\n",
        "\n",
        "    print(f'Modelo salvo nos arquivos: \"{json_file_path}\" e \"{h5_file_path}\" ')\n",
        "\n",
        "def load_model(file_name, load_dir):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "\n",
        "        print(f'Modelo construído a partir dos arquivos: \"{json_file_path}\" e \"{h5_file_path}\"')\n",
        "\n",
        "    else:\n",
        "        print(\n",
        "            f'Arquivos não encontrados: \"{(file_name + \".json\")}\" e \"{(file_name + \".h5\")}\", na pasta \"{load_dir}\"'\n",
        "        )\n",
        "\n",
        "    return loaded_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "_9b0an3PObPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas manuais"
      ],
      "metadata": {
        "id": "UlEma1WCF49k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "cHLZZaBVF9vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "HpUXCOL2GABF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def inter_union_sum(y_true, y_pred):\n",
        "    # W,H axes of each image\n",
        "    axes = (1,2)\n",
        "    \n",
        "    intersection = K.sum(K.abs(y_pred * y_true), axis=axes)\n",
        "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection\n",
        "\n",
        "    return intersection, union, mask_sum"
      ],
      "outputs": [],
      "metadata": {
        "id": "RMc9OGrhGeoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def dice_metric(y_true, y_pred):\n",
        "    # 2*|A & B| / (|A| + |B|)\n",
        "    intersection, _, mask_sum = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    dice = 2 * (intersection + SMOOTH)/(mask_sum + SMOOTH)\n",
        "\n",
        "    return K.mean(dice)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F82GF0c8HNye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def jaccard_metric(y_true, y_pred):\n",
        "    # |A & B| / (| A U B|)\n",
        "    intersection, union, _ = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    jaccard = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "\n",
        "    return K.mean(jaccard)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GPs64AkvH3S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura proposto por Ulas"
      ],
      "metadata": {
        "id": "MP_30iwQG5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "zYDwVYDzHXos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import swish\n",
        "from tensorflow.keras.layers import (Activation, AveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D,\n",
        "                                     UpSampling2D, concatenate)\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNa9WsFXHDqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_item_dense_layer(inputs, filters, kernel):\n",
        "    conv = Conv2D(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel,\n",
        "        padding='same',\n",
        "        use_bias=False\n",
        "    )(inputs)\n",
        "    bn = BatchNormalization()(conv)\n",
        "    act = Activation(swish)(bn)\n",
        "\n",
        "    return act"
      ],
      "outputs": [],
      "metadata": {
        "id": "zh84s9GzHl_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_dense_layer(input, conv_confs):\n",
        "    fst = _get_ulas_item_dense_layer(input, *conv_confs[0])\n",
        "    snd = _get_ulas_item_dense_layer(concatenate([input, fst]), *conv_confs[1])\n",
        "    trd = _get_ulas_item_dense_layer(concatenate([input, fst, snd]), *conv_confs[2])\n",
        "    frt = _get_ulas_item_dense_layer(concatenate([input, fst, snd, trd]), *conv_confs[3])\n",
        "\n",
        "    return frt"
      ],
      "outputs": [],
      "metadata": {
        "id": "rVOVnG5QHoWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_ulas_model(num_classes=1, pool_size=POOL_SIZE):\n",
        "    input = Input(\n",
        "        shape=(IMG_SZ, IMG_SZ, INPUT_CHANNELS),\n",
        "        dtype='float32'\n",
        "    )\n",
        "\n",
        "    # 1º parte do encoder\n",
        "    dense1 = _get_ulas_dense_layer(\n",
        "        input,\n",
        "        [\n",
        "            (160, (3, 7)),\n",
        "            (112, (3, 7)),\n",
        "            (144, (9, 7)),\n",
        "            (80, (3, 11)),\n",
        "        ]\n",
        "    )\n",
        "    trans1 = MaxPooling2D(pool_size=(pool_size, pool_size))(dense1)\n",
        "\n",
        "    # 2º parte do encoder\n",
        "    dense2 = _get_ulas_dense_layer(\n",
        "        trans1, \n",
        "        [\n",
        "            (144, (3, 5)),\n",
        "            (176, (7, 1)),\n",
        "            (144, (9, 9)),\n",
        "            (96, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "    trans2 = AveragePooling2D(pool_size=(pool_size, pool_size))(dense2)\n",
        "\n",
        "    # 1º parte da ponte\n",
        "    dense3 = _get_ulas_dense_layer(\n",
        "        trans2, \n",
        "        [\n",
        "            (176, (1, 1)),\n",
        "            (128, (3, 5)),\n",
        "            (208, (7, 7)),\n",
        "            (212, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte da ponte\n",
        "    dense4 = _get_ulas_dense_layer(\n",
        "        dense3, \n",
        "        [\n",
        "            (64, (1, 7)),\n",
        "            (208, (3, 5)),\n",
        "            (64, (9, 5)),\n",
        "            (208, (7, 9)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 1º parte do decoder\n",
        "    trans3 = UpSampling2D(size=(pool_size, pool_size))(dense4)\n",
        "    dense5 = _get_ulas_dense_layer(\n",
        "        trans3, \n",
        "        [\n",
        "            (208, (5, 7)),\n",
        "            (64, (3, 5)),\n",
        "            (96, (11, 11)),\n",
        "            (112, (7, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte do decoder\n",
        "    trans4 = UpSampling2D(size=(pool_size, pool_size))(dense5)\n",
        "    dense6 = _get_ulas_dense_layer(\n",
        "        trans4, \n",
        "        [\n",
        "            (128, (5, 5)),\n",
        "            (80, (11, 7)),\n",
        "            (64, (1, 1)),\n",
        "            (16, (3, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    final = Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(3, 7),\n",
        "        padding='same',\n",
        "        activation='softmax',\n",
        "    )(dense6)\n",
        "\n",
        "    model = Model(inputs=input, outputs=final)\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "u4qjBkYZHid4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# def get_ulas_model_v2(num_classes=1, pool_size=POOL_SIZE):\n",
        "#     return get_ulas_model(num_classes, pool_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "b14PiX4ldFO2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_ulas_model_dice_loss(num_classes=1, pool_size=POOL_SIZE):\n",
        "    return get_ulas_model(num_classes, pool_size)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências de Treinamento\n",
        "\n"
      ],
      "metadata": {
        "id": "iIDrnFqqI8yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "TKGfQssKJOes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from segmentation_models.losses import DiceLoss, CategoricalFocalLoss\n",
        "from segmentation_models.metrics import IOUScore, FScore"
      ],
      "outputs": [],
      "metadata": {
        "id": "3-8d_PzFJQ_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=INIT_LEARNING_RATE\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9KNRADbkJjxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def loss_func(class_weights):\n",
        "    dice_loss = DiceLoss(class_weights=class_weights, smooth=SMOOTH)\n",
        "    # focal_loss = CategoricalFocalLoss(gamma=FOCAL_LOSS_GAMA)\n",
        "\n",
        "    return dice_loss\n",
        "    # return focal_loss\n",
        "    # return dice_loss + focal_loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "bUKz7pdSFM2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def metric_func(class_weights):\n",
        "    return [\n",
        "        dice_metric,\n",
        "        jaccard_metric,\n",
        "        'accuracy',\n",
        "        'categorical_accuracy',\n",
        "        MeanIoU(num_classes=CLASSES_CNT),\n",
        "        IOUScore(class_weights=class_weights, smooth=SMOOTH, threshold=METRIC_THRESHOLD),\n",
        "        FScore(smooth=SMOOTH, threshold=METRIC_THRESHOLD)\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "rHnUtiZKHG9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def compile_model(model, class_weights=[]):\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        # 'categorical_crossentropy' | 'sparse_categorical_crossentropy'\n",
        "        # https://keras.io/api/losses/probabilistic_losses/\n",
        "        # loss='categorical_crossentropy',\n",
        "        loss=loss_func(class_weights),\n",
        "        # https://keras.io/api/metrics/\n",
        "        metrics=metric_func(class_weights),\n",
        "        run_eagerly=True\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tFE1qbESJpsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "kXTmW4Fc0RGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epoch_milestone = ModelCheckpoint(\n",
        "    STEPS_FILENAME,\n",
        "    monitor=f'val_{EVAL_METRIC}',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xm2EhKXtLS5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOP_PATIENCE,\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "p29VDRt5LTvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "csv_logger = CSVLogger(\n",
        "    CSV_LOG_FILENAME,\n",
        "    separator=';',\n",
        "    append=True,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNCOR_CDLUwg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=LR_REDUCER_PATIENCE,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    factor=1e-1,\n",
        "    verbose=1\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ea-WROIfMSIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "callbacks = [\n",
        "    epoch_milestone,\n",
        "    early_stop,\n",
        "    csv_logger,\n",
        "    lr_reducer,\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ec8Tejy7NAgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando dados\n",
        "\n"
      ],
      "metadata": {
        "id": "eM2eHxDXYaBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "2vWJJxjQsFHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_cnt, train_img_filenames = check_cnt(TRAINING_DIR)\n",
        "train_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27wkIDcPlIvk",
        "outputId": "c74dd2a3-b070-488e-fd76-1ec9494b71d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_cnt, xval_img_filenames = check_cnt(X_VAL_DIR)\n",
        "xval_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9dNLmoTnccA",
        "outputId": "5c8f8a28-43de-4ecd-d58d-3e1208e3843c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_cnt, test_img_filenames = check_cnt(TEST_DIR)\n",
        "test_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xmGpodMnbjK",
        "outputId": "d1d0a1cc-5416-47e1-ee4b-ccdd7a38418d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "there_are_preload_data = all([train_cnt, test_cnt, xval_cnt])\n",
        "there_are_preload_data"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGw8uGkNoD6m",
        "outputId": "ca02628d-2565-4f26-9220-68b8ae4c90a8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedimentos na ausência de dados"
      ],
      "metadata": {
        "id": "ae61zcz2n47-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    create_data()"
      ],
      "outputs": [],
      "metadata": {
        "id": "U97IDRZ4odfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    # classes_weight = load_classes_weight(raw_train_labels)\n",
        "    classes_weight = load_classes_weight()\n",
        "else:\n",
        "    classes_weight = load_classes_weight()\n",
        "\n",
        "print(f'classes_weight:\\n{classes_weight}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm2tBF0Zoq9Y",
        "outputId": "935d550c-7ba7-4ac7-a874-11755f5e32c6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_cnt, train_img_filenames = check_cnt(TRAINING_DIR)\n",
        "\n",
        "    xval_cnt, xval_img_filenames = check_cnt(X_VAL_DIR)\n",
        "\n",
        "    test_cnt, test_img_filenames = check_cnt(TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QVzsy8AQCqsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    del train_img_filenames\n",
        "    train_dataset = get_dataset(TRAINING_DIR, DT_SHUFFLE_SZ, should_data_aug=True)\n",
        "\n",
        "train_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "2XyC1fQoYmpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    del xval_img_filenames\n",
        "    xval_dataset = get_dataset(X_VAL_DIR)\n",
        "\n",
        "xval_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "C445gwTDJ1Dx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    del test_img_filenames\n",
        "    test_dataset = get_dataset(TEST_DIR)\n",
        "\n",
        "test_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "6RejhvbCJtzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualização teste"
      ],
      "metadata": {
        "id": "X4Pej9qVUj_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "dGKB02ykFt9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(train_gen) - 1)\n",
        "\n",
        "# img_batch, mask_batch = train_gen.__getitem__(r_ind)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ux8r0iPgCz26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(img_batch) - 1)\n",
        "\n",
        "# sample_image, sample_mask = img_batch[r_ind], mask_batch[r_ind]\n",
        "\n",
        "# print('image', sample_image.dtype, sample_image.shape)\n",
        "# print('mask', sample_mask.dtype, sample_mask.shape)\n",
        "\n",
        "# display_sample([sample_image, sample_mask])"
      ],
      "outputs": [],
      "metadata": {
        "id": "dQo_5QgrwSi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando model"
      ],
      "metadata": {
        "id": "hRDKvbFVwLL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "t1LhMMmt-xNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "euPOixtlyVql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "get_model = f'get_{MODEL_FILENAME}'"
      ],
      "outputs": [],
      "metadata": {
        "id": "PGqgBSc_yXWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "clear_session()"
      ],
      "outputs": [],
      "metadata": {
        "id": "HVxPNvJSyZAA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = load_model(MODEL_FILENAME, MODEL_DIR) or eval(get_model)(CLASSES_CNT)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hK-2y3zpyanu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a0080c-dc30-451d-b251-ff8fcfdd64f6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = compile_model(model, classes_weight)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0_26VypCygR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gHZNGULAybLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5frUAbo7yinL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25760dc4-7734-458f-efcf-99e273969526"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get_model_memory_usage(BATCH_SIZE, model)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# keras_model_memory_usage_in_bytes(model, batch_size=BATCH_SIZE)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    to_file=PLOT_FILENAME,\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=True,\n",
        "    dpi=120,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fRnLBHq0ykSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0a929a-3e62-44d0-a6f6-8b770d45cd38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização prévia"
      ],
      "metadata": {
        "id": "NHNgrwTVUFzc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "cx1lZwgZUKNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i_ooPSRWULIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b58fbdb-48a0-4e56-8109-dd7d07712bf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(train_gen) - 1)\n",
        "\n",
        "# img_batch, mask_batch = train_gen.__getitem__(r_ind)"
      ],
      "outputs": [],
      "metadata": {
        "id": "IaVstKaQC_Yu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# for image, mask in test_dataset.take(1):\n",
        "#     sample_image, sample_mask = image, mask\n",
        "\n",
        "# predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "\n",
        "# print('input', sample_image[0].dtype, sample_image[0].shape)\n",
        "# print('mask', sample_mask[0].dtype, sample_mask[0].shape)\n",
        "# print('pred', predict_img[0].dtype, predict_img[0].shape)\n",
        "\n",
        "# display_sample([sample_image[0], sample_mask[0], predict_img[0]], to_save=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2Bw5FogZCw_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "s1agFI3Xyrws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_PER_EPOCH = int((train_cnt // BATCH_SIZE) * .4)\n",
        "DATA = train_dataset\n",
        "\n",
        "STEPS_PER_EPOCH"
      ],
      "outputs": [],
      "metadata": {
        "id": "oQSEOwFJBgeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b508e522-e3a3-4f75-d9af-ddc1183ec155"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_STEPS = int((xval_cnt // BATCH_SIZE) * .5)\n",
        "XVAL_DATA = xval_dataset\n",
        "\n",
        "VALIDATION_STEPS "
      ],
      "outputs": [],
      "metadata": {
        "id": "-_TczQjUCDyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae653160-5dbc-4ec9-c4d2-0ab6e34cbf71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results = model.fit(\n",
        "    DATA,\n",
        "    initial_epoch=INITAL_EPOCH,\n",
        "    epochs=MAX_EPOCH,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    validation_data=XVAL_DATA,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OLvwUI35y2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369268e5-0337-46fd-8bc2-25d404c3e09e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mMuC0wdQy4W2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(results.history)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QF7moJWny6cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização final"
      ],
      "metadata": {
        "id": "mZjKdfiev5pT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "MZGDnqMdwCW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "60PKi14rwFbp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for image, mask in test_dataset.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "\n",
        "display_sample([sample_image[0], sample_mask[0], predict_img[0]], to_save=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4QKo8VcjwX7y"
      }
    }
  ]
}