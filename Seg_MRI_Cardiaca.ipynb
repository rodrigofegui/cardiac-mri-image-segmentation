{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seg_MRI_Cardiaca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HC4K3T4SmEf_",
        "eKFfei90mcAJ",
        "jRA4xxMDuLRG",
        "hcEtyDUbOIcw",
        "UlEma1WCF49k",
        "MP_30iwQG5Pf",
        "iIDrnFqqI8yY",
        "qIKOaglsNMAN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC4K3T4SmEf_"
      },
      "source": [
        "# **Segmentação de MRI Cardíacas**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKFfei90mcAJ"
      },
      "source": [
        "# Dependências"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z14WjMKNmnIS"
      },
      "source": [
        "Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfB9dnKSl-VP"
      },
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "!pip install scikit-learn==0.24.2\n",
        "!pip install segmentation-models==1.0.1\n",
        "\n",
        "!pip install nibabel==3.2.1\n",
        "!pip install MedPy==0.4.0\n",
        "\n",
        "!pip install matplotlib==3.2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHCSwCdnIHQ"
      },
      "source": [
        "Acesso à arquivos do Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQl43uvenSLS"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = [\n",
        "    '/content/drive',\n",
        "    'My Drive/Colab Notebooks/data'\n",
        "]\n",
        "\n",
        "drive.mount(drive_path[0], force_remount=True)\n",
        "os.chdir('/'.join(drive_path))\n",
        "sys.path.append('/'.join(drive_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAnelmOnebU"
      },
      "source": [
        "Visualização da GPU disponibilizada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TmRxKiCnnCr"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HRMYmjznryn"
      },
      "source": [
        "Visualizando a quantidade de GPUs detectadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNVZRezpnwlV"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f'GPUs available: {len(gpus)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBDBgymJoECi"
      },
      "source": [
        "Configuração de uso gradual e necessário da memória da GPU utilizada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcgIaH9XoE5r"
      },
      "source": [
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f'{len(gpus)} physical GPUs vs. {len(logical_gpus)} logical GPUs')\n",
        "        \n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnCLKLG9og3I"
      },
      "source": [
        "# Constantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNe0BZkHokLU"
      },
      "source": [
        "IMG_SZ = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FRgMFMDo1UC"
      },
      "source": [
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FiWg76aptvV"
      },
      "source": [
        "Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AJ4EW5HCRpe"
      },
      "source": [
        "PATCH_STEP = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwnnmbtnn3_S"
      },
      "source": [
        "DT_BUFFER_SZ = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rKj41ofVL5x"
      },
      "source": [
        "VALIDATION_PROPORTION = .25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-UDTg4lo7GY"
      },
      "source": [
        "XVALIDATION_PROPORTION = .25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZ1vFnBo86-"
      },
      "source": [
        "# represent voxels located in the:\n",
        "# 0: background\n",
        "# 1: RV cavity\n",
        "# 2: myocardium\n",
        "# 3: LV cavity \n",
        "CLASSES_CNT = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhPLtcgFIBS8"
      },
      "source": [
        "INPUT_CHANNELS = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FypEp4tTqFOz"
      },
      "source": [
        "TRAINING_FILENAME = 'training.zip'\n",
        "TRAINING_DIR = 'ACDC/train'\n",
        "\n",
        "TRAINING_FILENAME = os.path.join(*drive_path, TRAINING_FILENAME)\n",
        "TRAINING_DIR = os.path.join(*drive_path, TRAINING_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5tTzWDkqmFU"
      },
      "source": [
        "Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE7z_CNNqoiu"
      },
      "source": [
        "MODEL_FILENAME = 'ulas_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW8kwOYwqsS2"
      },
      "source": [
        "MODEL_DIR = os.path.join(*drive_path, MODEL_FILENAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lEQdpd8K_la"
      },
      "source": [
        "Arquitetura Ulas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPkeN2YyLCtL"
      },
      "source": [
        "POOL_SIZE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_VUxpZxt5IE"
      },
      "source": [
        "Métricas e Funções de perda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpy8ho6IGiTL"
      },
      "source": [
        "SMOOTH = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHWuvgnRt4Vx"
      },
      "source": [
        "TVERSKY_FN_WEIGHT = .7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMmOYOCnt_Gg"
      },
      "source": [
        "TVERSKY_FOCAL = .5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0NCWDkVuDMP"
      },
      "source": [
        "FOCAL_LOSS_GAMA = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abjYtJ7zp2Bj"
      },
      "source": [
        "Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPy_ujYcpDiT"
      },
      "source": [
        "INIT_LEARNING_RATE = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DExT9SdYpNCm"
      },
      "source": [
        "MIN_LEARNING_RATE = 1e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAAyIdURprUw"
      },
      "source": [
        "BATCH_SIZE = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MGb3tctlHvb"
      },
      "source": [
        "INITAL_EPOCH = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm_NFCiKSIrZ"
      },
      "source": [
        "MAX_EPOCH = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7LBrU0Ptpw9"
      },
      "source": [
        "MAIN_METRIC = 'dice_metric'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIERQ-Kqtt3Z"
      },
      "source": [
        "if MODEL_FILENAME == 'unet_plusplus_model':\n",
        "    EVAL_METRIC = f're_lu_{MAIN_METRIC}'\n",
        "else:\n",
        "    EVAL_METRIC = MAIN_METRIC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDXFT87zPDUH"
      },
      "source": [
        "Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPQ6ps85PF76"
      },
      "source": [
        "AUG_ROTATION = 90"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPicNXYUPKVZ"
      },
      "source": [
        "AUG_W_HOR_FLIP = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3hQd0c_PP7K"
      },
      "source": [
        "AUG_W_VER_FLIP = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwViSbPsPdpy"
      },
      "source": [
        "AUG_WIDTH_RNG = .4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtBEysfLPfoY"
      },
      "source": [
        "AUG_HEIGHT_RNG = .4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWvTb7owPgaN"
      },
      "source": [
        "AUG_ZOOM = [1, 1.6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40y_uDu-PhU6"
      },
      "source": [
        "AUG_FILL_MODE = 'wrap'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_lgkcSdrq25"
      },
      "source": [
        "Milestones do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp0RTecqsvC5"
      },
      "source": [
        "EARLY_STOP_PATIENCE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__8-O_YPMhMI"
      },
      "source": [
        "LR_REDUCER_PATIENCE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asIAvRtHs5Rh"
      },
      "source": [
        "STEPS_FILENAME = os.path.join(\n",
        "    MODEL_DIR,\n",
        "    f'{MODEL_FILENAME}.h5'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8OTM6KNs-vk"
      },
      "source": [
        "CSV_LOG_FILENAME = os.path.join(MODEL_DIR, f'{MODEL_FILENAME}_log.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkYM5QDBtPul"
      },
      "source": [
        "Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAkIzuNPtOzR"
      },
      "source": [
        "PLOT_FILENAME = f'{MODEL_FILENAME}_structure.png'\n",
        "PLOT_FILENAME = os.path.join(MODEL_DIR, PLOT_FILENAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8k9BznKtWcu"
      },
      "source": [
        "PLOT_WIDTH = 720"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRA4xxMDuLRG"
      },
      "source": [
        "# Aquisição das imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLKawJgfvLcm"
      },
      "source": [
        "Imports desta seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DctGw4bvN7t"
      },
      "source": [
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.image import extract_patches\n",
        "from tensorflow.keras.utils import normalize, to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fosux3OuQkB"
      },
      "source": [
        "\"\"\"\n",
        "author: Clément Zotti (clement.zotti@usherbrooke.ca)\n",
        "date: April 2017\n",
        "\n",
        "DESCRIPTION :\n",
        "The script provide helpers functions to handle nifti image format:\n",
        "    - load_nii()\n",
        "    - save_nii()\n",
        "\n",
        "to generate metrics for two images:\n",
        "    - metrics()\n",
        "\n",
        "And it is callable from the command line (see below).\n",
        "Each function provided in this script has comments to understand\n",
        "how they works.\n",
        "\n",
        "HOW-TO:\n",
        "\n",
        "This script was tested for python 3.4.\n",
        "\n",
        "First, you need to install the required packages with\n",
        "    pip install -r requirements.txt\n",
        "\n",
        "After the installation, you have two ways of running this script:\n",
        "    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n",
        "    2) python metrics.py ground_truth/ prediction/\n",
        "\n",
        "The first option will print in the console the dice and volume of each class for the given image.\n",
        "The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n",
        "\n",
        "\n",
        "Based on: http://acdc.creatis.insa-lyon.fr\n",
        "\"\"\"\n",
        "#\n",
        "# Utils function to load and save nifti files with the nibabel package\n",
        "#\n",
        "def load_nii(img_path):\n",
        "    \"\"\"\n",
        "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
        "    everyting needed to save another 'nii' or 'nii.gz'\n",
        "    in the same dimensional space, i.e. the affine matrix and the header\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Three element, the first is a numpy array of the image values,\n",
        "    the second is the affine transformation of the image, and the\n",
        "    last one is the header of the image.\n",
        "    \"\"\"\n",
        "    nimg = nib.load(img_path)\n",
        "    return nimg.get_fdata().astype('float32'), nimg.affine, nimg.header\n",
        "\n",
        "def save_nii(img_path, data, affine, header):\n",
        "    \"\"\"\n",
        "    Function to save a 'nii' or 'nii.gz' file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
        "\n",
        "    data: np.array\n",
        "    Numpy array of the image data.\n",
        "\n",
        "    affine: list of list or np.array\n",
        "    The affine transformation to save with the image.\n",
        "\n",
        "    header: nib.Nifti1Header\n",
        "    The header that define everything about the data\n",
        "    (pleasecheck nibabel documentation).\n",
        "    \"\"\"\n",
        "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
        "    nimg.to_filename(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rDOEKiCvsVz"
      },
      "source": [
        "def file_paths(base_dir):\n",
        "    c_paths = {\n",
        "        'config': [],\n",
        "        'ground_truth': [],\n",
        "        'images': [],\n",
        "        '4d': []\n",
        "    }\n",
        "\n",
        "    for c_dir, next_dirs, file_names in os.walk(base_dir):\n",
        "        # skip root\n",
        "        if next_dirs:\n",
        "            continue\n",
        "\n",
        "        c_patient = os.path.basename(c_dir)\n",
        "\n",
        "        for f_n in file_names:\n",
        "            f_n = os.path.join(c_dir, f_n)\n",
        "\n",
        "            if f_n.endswith('.cfg'): file_type = 'config'\n",
        "            elif '_gt' in f_n: file_type = 'ground_truth'\n",
        "            elif '_4d' in f_n: file_type = '4d'\n",
        "            else: file_type = 'images'\n",
        "\n",
        "            c_paths[file_type].append(f_n)\n",
        "\n",
        "    for file_type in c_paths.keys():\n",
        "        c_paths[file_type].sort()\n",
        "\n",
        "    return c_paths\n",
        "\n",
        "def load_data(file_paths, is_training=True):\n",
        "    images_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_data.npy')\n",
        "    gt_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_gt_data.npy')\n",
        "\n",
        "    try:\n",
        "        imgs = np.load(images_filename, allow_pickle=True)\n",
        "        imgs_gt = np.load(gt_filename, allow_pickle=True)\n",
        "\n",
        "        if np.any(imgs) and np.any(imgs_gt):\n",
        "            print('carregado dos arquivos')\n",
        "\n",
        "            return tf.convert_to_tensor(imgs), tf.convert_to_tensor(imgs_gt, dtype=tf.float32)\n",
        "    except:\n",
        "        print('carregando arquivos')\n",
        "        imgs, imgs_gt =  _load_data(file_paths)\n",
        "\n",
        "        np.save(images_filename, imgs)\n",
        "        np.save(gt_filename, imgs_gt)\n",
        "\n",
        "        return imgs, imgs_gt\n",
        "\n",
        "def _load_data(file_paths):\n",
        "    images, ground_truth = [], []\n",
        "    cnt = 1\n",
        "\n",
        "    for c_img, c_ground_truth in zip(file_paths['images'], file_paths['ground_truth']):\n",
        "        print(f'processing {cnt}...')\n",
        "\n",
        "        # we load 3D training image\n",
        "        training_image, _, _ = load_nii(c_img)\n",
        "        # we load 3D training mask (shape=(512,512,129))\n",
        "        train_ground_truth, _, _ = load_nii(c_ground_truth)\n",
        "\n",
        "        for k in range(min(train_ground_truth.shape[-1], training_image.shape[-1])):\n",
        "            #axial cuts are made along the z axis with undersampling\n",
        "            gt_2d = np.array(train_ground_truth[::, ::, k])\n",
        "\n",
        "            # invalid ground truth\n",
        "            if len(np.unique(gt_2d)) == 1:\n",
        "                continue\n",
        "\n",
        "            image_patches = _extract_patches(\n",
        "                _pre_process_img(np.array(training_image[::, ::, k]))\n",
        "            )\n",
        "            gt_patches = _extract_patches(gt_2d)\n",
        "\n",
        "            if (tf.size(images) == 0).numpy():\n",
        "                images = image_patches\n",
        "            else:\n",
        "                images = tf.concat((images, image_patches), axis=0)\n",
        "\n",
        "            if (tf.size(ground_truth) == 0).numpy():\n",
        "                ground_truth = gt_patches\n",
        "            else:\n",
        "                ground_truth = tf.concat((ground_truth, gt_patches), axis=0)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "    return images, ground_truth\n",
        "\n",
        "def _extract_patches(image_2d):\n",
        "    image_2d = tf.expand_dims(tf.expand_dims(image_2d, axis=-1), axis=0)\n",
        "\n",
        "    if image_2d.shape[1] < IMG_SZ or image_2d.shape[2] < IMG_SZ:\n",
        "        return tf.image.resize(\n",
        "            image_2d, (IMG_SZ, IMG_SZ), method='nearest'\n",
        "        )\n",
        "\n",
        "    image_patches = extract_patches(\n",
        "        image_2d,\n",
        "        sizes=[1, IMG_SZ, IMG_SZ, 1],\n",
        "        strides=[1, PATCH_STEP, PATCH_STEP, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    return tf.reshape(\n",
        "        image_patches,\n",
        "        [image_patches.shape[1] * image_patches.shape[2], IMG_SZ, IMG_SZ, 1]\n",
        "    )\n",
        "\n",
        "# Based on: https://github.com/MinaJf/FU-net/blob/HEAD/image_loder.py\n",
        "def _pre_process_img(img):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # standardization (zero mean)\n",
        "    img -= tf.math.reduce_mean(img)\n",
        "    img /= tf.math.reduce_std(img)\n",
        "\n",
        "    # normalize between [0, 1]\n",
        "    img -= tf.math.reduce_min(img)\n",
        "    img /= tf.math.reduce_max(img)\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcEtyDUbOIcw"
      },
      "source": [
        "# Modelo em mémoria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_mBzEfeOOaj"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFteRO3KOQfj"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9b0an3PObPA"
      },
      "source": [
        "# Based on: https://github.com/mjbhobe/dl-tensorflow-keras/blob/master/kr_helper_funcs.py\n",
        "def save_model(model, file_name, save_dir):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"\n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(f'Não foi possível criar o repositório \"{save_dir}\", para salvar o modelo. Terminando a execução!')\n",
        "            raise err\n",
        "\n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (file_name + '.h5'))\n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save(\n",
        "        h5_file_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "        save_traces=True,\n",
        "    )\n",
        "\n",
        "    print(f'Modelo salvo nos arquivos: \"{json_file_path}\" e \"{h5_file_path}\" ')\n",
        "\n",
        "def load_model(file_name, load_dir):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "\n",
        "        print(f'Modelo construído a partir dos arquivos: \"{json_file_path}\" e \"{h5_file_path}\"')\n",
        "\n",
        "    else:\n",
        "        print(\n",
        "            f'Arquivos não encontrados: \"{(file_name + \".json\")}\" e \"{(file_name + \".h5\")}\", na pasta \"{load_dir}\"'\n",
        "        )\n",
        "\n",
        "    return loaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBnxc1TaUIsT"
      },
      "source": [
        "# Carregando dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJBLyaJoUSef"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCDybhaqURto"
      },
      "source": [
        "from random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import unique\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAtsCK5AnFJF"
      },
      "source": [
        "def to_dataset(data, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "    dataset = dataset.shuffle(\n",
        "        buffer_size=DT_BUFFER_SZ,\n",
        "        seed=RANDOM_SEED,\n",
        "        reshuffle_each_iteration=True\n",
        "    )\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(2)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgYXN9Mz5Lpl"
      },
      "source": [
        "training_paths = file_paths(TRAINING_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywop8DyCka3Y"
      },
      "source": [
        "print(len(training_paths['config']))\n",
        "print(len(training_paths['ground_truth']))\n",
        "print(len(training_paths['images']))\n",
        "print(len(training_paths['4d']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRbfZ2Mw6Jmh"
      },
      "source": [
        "raw_train_data, raw_train_labels = load_data(training_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ4UDaVRGYrw"
      },
      "source": [
        "print(f'raw_train_data: {raw_train_data.shape}\\n\\t{raw_train_data.dtype}')\n",
        "print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEQASGF_bFW8"
      },
      "source": [
        "classes_weight = compute_class_weight(\n",
        "    'balanced',\n",
        "    unique(raw_train_labels),\n",
        "    tf.reshape(raw_train_labels, tf.size(raw_train_labels)).numpy()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTr9988Rb7Du"
      },
      "source": [
        "print(f'classes_weight: {len(classes_weight)}\\n{classes_weight}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC3AagLlbY9u"
      },
      "source": [
        "raw_train_labels = to_categorical(raw_train_labels, CLASSES_CNT)\n",
        "print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h82EnnK7Uxls"
      },
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    raw_train_data.numpy(), raw_train_labels,\n",
        "    test_size=VALIDATION_PROPORTION,\n",
        "    random_state=RANDOM_SEED\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOV5wKxOV71r"
      },
      "source": [
        "print(f'test_data: {test_data.shape}')\n",
        "print(f'test_labels: {test_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TILS5we-WH6M"
      },
      "source": [
        "train_data, xval_data, train_labels, xval_labels = train_test_split(\n",
        "    train_data, train_labels,\n",
        "    test_size=XVALIDATION_PROPORTION,\n",
        "    random_state=RANDOM_SEED\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoRxciPWSAi"
      },
      "source": [
        "print(f'train_data: {train_data.shape} - {train_data.dtype}')\n",
        "print(f'xval_data: {xval_data.shape} - {xval_data.dtype}')\n",
        "print(f'train_labels: {train_labels.shape} - {train_labels.dtype}')\n",
        "print(f'xval_labels: {xval_labels.shape} - {xval_labels.dtype}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TDvEa1goyJb"
      },
      "source": [
        "# train_dataset = to_dataset(train_data, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrdS_4yAo4B8"
      },
      "source": [
        "# xval_dataset = to_dataset(xval_data, xval_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkfqjoc3o4b-"
      },
      "source": [
        "# test_dataset = to_dataset(test_data, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dOZ5954W5Df"
      },
      "source": [
        "Pré-visualização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rx_lhqAYyoN"
      },
      "source": [
        "rnd_idx = randint(0, len(train_data) - 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2)\n",
        "\n",
        "train_img = tf.squeeze(train_data[rnd_idx], axis=2)\n",
        "train_gt = tf.argmax(train_labels[rnd_idx], axis=2)\n",
        "\n",
        "axes[0].imshow(train_img, cmap='hot')\n",
        "axes[1].imshow(train_gt, cmap='hot')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlEma1WCF49k"
      },
      "source": [
        "# Métricas manuais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLZZaBVF9vm"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUXCOL2GABF"
      },
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMc9OGrhGeoX"
      },
      "source": [
        "def inter_union_sum(y_true, y_pred):\n",
        "    # W,H axes of each image\n",
        "    axes = (1,2)\n",
        "    \n",
        "    intersection = K.sum(K.abs(y_pred * y_true), axis=axes)\n",
        "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection\n",
        "\n",
        "    return intersection, union, mask_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F82GF0c8HNye"
      },
      "source": [
        "def dice_metric(y_true, y_pred):\n",
        "    # 2*|A & B| / (|A| + |B|)\n",
        "    intersection, _, mask_sum = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    dice = 2 * (intersection + SMOOTH)/(mask_sum + SMOOTH)\n",
        "\n",
        "    return K.mean(dice)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPs64AkvH3S4"
      },
      "source": [
        "def jaccard_metric(y_true, y_pred):\n",
        "    # |A & B| / (| A U B|)\n",
        "    intersection, union, _ = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    jaccard = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "\n",
        "    return K.mean(jaccard)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP_30iwQG5Pf"
      },
      "source": [
        "# Arquitetura proposto por Ulas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYDwVYDzHXos"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNa9WsFXHDqE"
      },
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import swish\n",
        "from tensorflow.keras.layers import (Activation, AveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D,\n",
        "                                     UpSampling2D, concatenate)\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh84s9GzHl_g"
      },
      "source": [
        "def _get_ulas_item_dense_layer(inputs, filters, kernel):\n",
        "    conv = Conv2D(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel,\n",
        "        padding='same',\n",
        "        use_bias=False\n",
        "    )(inputs)\n",
        "    bn = BatchNormalization()(conv)\n",
        "    act = Activation(swish)(bn)\n",
        "\n",
        "    return act"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVOVnG5QHoWx"
      },
      "source": [
        "def _get_ulas_dense_layer(input, conv_confs):\n",
        "    fst = _get_ulas_item_dense_layer(input, *conv_confs[0])\n",
        "    snd = _get_ulas_item_dense_layer(concatenate([input, fst]), *conv_confs[1])\n",
        "    trd = _get_ulas_item_dense_layer(concatenate([input, fst, snd]), *conv_confs[2])\n",
        "    frt = _get_ulas_item_dense_layer(concatenate([input, fst, snd, trd]), *conv_confs[3])\n",
        "\n",
        "    return frt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4qjBkYZHid4"
      },
      "source": [
        "def get_ulas_model(num_classes=1, pool_size=POOL_SIZE):\n",
        "    input = Input(\n",
        "        shape=(IMG_SZ, IMG_SZ, INPUT_CHANNELS),\n",
        "        dtype='float32'\n",
        "    )\n",
        "\n",
        "    # 1º parte do encoder\n",
        "    dense1 = _get_ulas_dense_layer(\n",
        "        input,\n",
        "        [\n",
        "            (160, (3, 7)),\n",
        "            (112, (3, 7)),\n",
        "            (144, (9, 7)),\n",
        "            (80, (3, 11)),\n",
        "        ]\n",
        "    )\n",
        "    trans1 = MaxPooling2D(pool_size=(pool_size, pool_size))(dense1)\n",
        "\n",
        "    # 2º parte do encoder\n",
        "    dense2 = _get_ulas_dense_layer(\n",
        "        trans1, \n",
        "        [\n",
        "            (144, (3, 5)),\n",
        "            (176, (7, 1)),\n",
        "            (144, (9, 9)),\n",
        "            (96, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "    trans2 = AveragePooling2D(pool_size=(pool_size, pool_size))(dense2)\n",
        "\n",
        "    # 1º parte da ponte\n",
        "    dense3 = _get_ulas_dense_layer(\n",
        "        trans2, \n",
        "        [\n",
        "            (176, (1, 1)),\n",
        "            (128, (3, 5)),\n",
        "            (208, (7, 7)),\n",
        "            (212, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte da ponte\n",
        "    dense4 = _get_ulas_dense_layer(\n",
        "        dense3, \n",
        "        [\n",
        "            (64, (1, 7)),\n",
        "            (208, (3, 5)),\n",
        "            (64, (9, 5)),\n",
        "            (208, (7, 9)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 1º parte do decoder\n",
        "    trans3 = UpSampling2D(size=(pool_size, pool_size))(dense4)\n",
        "    dense5 = _get_ulas_dense_layer(\n",
        "        trans3, \n",
        "        [\n",
        "            (208, (5, 7)),\n",
        "            (64, (3, 5)),\n",
        "            (96, (11, 11)),\n",
        "            (112, (7, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte do decoder\n",
        "    trans4 = UpSampling2D(size=(pool_size, pool_size))(dense5)\n",
        "    dense6 = _get_ulas_dense_layer(\n",
        "        trans4, \n",
        "        [\n",
        "            (128, (5, 5)),\n",
        "            (80, (11, 7)),\n",
        "            (64, (1, 1)),\n",
        "            (16, (3, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    final = Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(3, 7),\n",
        "        padding='same',\n",
        "        activation='softmax'\n",
        "    )(dense6)\n",
        "\n",
        "    model = Model(inputs=input, outputs=final)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIDrnFqqI8yY"
      },
      "source": [
        "# Dependências de Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKGfQssKJOes"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-8d_PzFJQ_a"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from segmentation_models.losses import DiceLoss, CategoricalFocalLoss\n",
        "from segmentation_models.metrics import IOUScore, FScore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNRADbkJjxH"
      },
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=INIT_LEARNING_RATE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--5ZhnlqO7fM"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=AUG_ROTATION,\n",
        "    horizontal_flip=AUG_W_HOR_FLIP,\n",
        "    vertical_flip=AUG_W_VER_FLIP,\n",
        "    width_shift_range=AUG_WIDTH_RNG,\n",
        "    height_shift_range=AUG_HEIGHT_RNG,\n",
        "    zoom_range=AUG_ZOOM,\n",
        "\tfill_mode=AUG_FILL_MODE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKz7pdSFM2H"
      },
      "source": [
        "def loss_func(class_weights):\n",
        "    dice_loss = DiceLoss(class_weights=class_weights, smooth=SMOOTH)\n",
        "    focal_loss = CategoricalFocalLoss()\n",
        "\n",
        "    return dice_loss + focal_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHnUtiZKHG9e"
      },
      "source": [
        "def metric_func(class_weights):\n",
        "    return [\n",
        "        dice_metric,\n",
        "        jaccard_metric,\n",
        "        'accuracy',\n",
        "        'categorical_accuracy',\n",
        "        MeanIoU(num_classes=CLASSES_CNT),\n",
        "        IOUScore(class_weights=class_weights, smooth=SMOOTH),\n",
        "        FScore(smooth=SMOOTH)\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFE1qbESJpsb"
      },
      "source": [
        "def compile_model(model, class_weights=[]):\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        # 'categorical_crossentropy' | 'sparse_categorical_crossentropy'\n",
        "        # https://keras.io/api/losses/probabilistic_losses/\n",
        "        # loss='categorical_crossentropy',\n",
        "        loss=loss_func(class_weights),\n",
        "        # https://keras.io/api/metrics/\n",
        "        metrics=metric_func(class_weights)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm2EhKXtLS5G"
      },
      "source": [
        "epoch_milestone = ModelCheckpoint(\n",
        "    STEPS_FILENAME,\n",
        "    monitor=f'val_{EVAL_METRIC}',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p29VDRt5LTvL"
      },
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOP_PATIENCE,\n",
        "    verbose=1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNCOR_CDLUwg"
      },
      "source": [
        "csv_logger = CSVLogger(\n",
        "    CSV_LOG_FILENAME,\n",
        "    separator=';',\n",
        "    append=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea-WROIfMSIv"
      },
      "source": [
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=LR_REDUCER_PATIENCE,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    factor=1e-1,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec8Tejy7NAgQ"
      },
      "source": [
        "callbacks = [\n",
        "    epoch_milestone,\n",
        "    early_stop,\n",
        "    csv_logger,\n",
        "    lr_reducer,\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIKOaglsNMAN"
      },
      "source": [
        "# Carregando model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-qx-689NL4s"
      },
      "source": [
        "Imports da seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ_Gh5gZNSpq"
      },
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhE7vAMrNcw1"
      },
      "source": [
        "get_model = f'get_{MODEL_FILENAME}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7VJSNVGNhh1"
      },
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "savVIwB7NklS"
      },
      "source": [
        "model = load_model(MODEL_FILENAME, MODEL_DIR) or eval(get_model)(CLASSES_CNT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChHBa5rk2Jt"
      },
      "source": [
        "# save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elROtY2fNnzV"
      },
      "source": [
        "model = compile_model(model, classes_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyLbo_j_N0aA"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XouGqq3cN4Bp"
      },
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    to_file=PLOT_FILENAME,\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=True,\n",
        "    dpi=120,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buOniuUnRzqg"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZE53-m4gy6-"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ecJ7qmR5YO"
      },
      "source": [
        "results = model.fit(\n",
        "    x=aug.flow(train_data, train_labels, batch_size=BATCH_SIZE, seed=RANDOM_SEED),\n",
        "    initial_epoch=INITAL_EPOCH,\n",
        "    epochs=MAX_EPOCH,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    validation_data=(xval_data, xval_labels),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv8AQlq-Svkq"
      },
      "source": [
        "save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTqdMD0aStFm"
      },
      "source": [
        "print(results.history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}