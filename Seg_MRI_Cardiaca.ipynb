{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Seg_MRI_Cardiaca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HC4K3T4SmEf_",
        "eKFfei90mcAJ",
        "EnCLKLG9og3I",
        "jRA4xxMDuLRG",
        "hcEtyDUbOIcw",
        "UlEma1WCF49k",
        "w7JKL6lA3CmT",
        "MP_30iwQG5Pf",
        "iIDrnFqqI8yY",
        "X4Pej9qVUj_u",
        "hRDKvbFVwLL0",
        "mZjKdfiev5pT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentação de MRI Cardíacas**\n",
        "\n"
      ],
      "metadata": {
        "id": "HC4K3T4SmEf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "eKFfei90mcAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas"
      ],
      "metadata": {
        "id": "z14WjMKNmnIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "\n",
        "!pip install scikit-learn==0.24.2\n",
        "!pip install segmentation-models==1.0.1\n",
        "\n",
        "!pip install nibabel==3.2.1\n",
        "!pip install MedPy==0.4.0\n",
        "\n",
        "!pip install matplotlib"
      ],
      "outputs": [],
      "metadata": {
        "id": "NfB9dnKSl-VP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c479d0-4084-4171-b44b-be9cbecba024"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acesso à arquivos do Gdrive"
      ],
      "metadata": {
        "id": "UzHCSwCdnIHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "drive_path = [\n",
        "    '/content/drive',\n",
        "    'My Drive/Colab Notebooks/data'\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "XNB6SCUQxhTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(drive_path[0], force_remount=True)\n",
        "os.chdir('/'.join(drive_path))\n",
        "sys.path.append('/'.join(drive_path))"
      ],
      "outputs": [],
      "metadata": {
        "id": "JQl43uvenSLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276f551a-d5dc-4493-d3f5-010c91e84b31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualização da GPU disponibilizada"
      ],
      "metadata": {
        "id": "9VAnelmOnebU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [],
      "metadata": {
        "id": "0TmRxKiCnnCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b061ea0-ec92-47a2-8508-9107a8f8deea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizando a quantidade de GPUs detectadas"
      ],
      "metadata": {
        "id": "9HRMYmjznryn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f'GPUs available: {len(gpus)}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "kNVZRezpnwlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0cb83c-ba2c-431f-dc87-52325c626a60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração de uso gradual e necessário da memória da GPU utilizada"
      ],
      "metadata": {
        "id": "tBDBgymJoECi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f'{len(gpus)} physical GPUs vs. {len(logical_gpus)} logical GPUs')\n",
        "        \n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GcgIaH9XoE5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constantes"
      ],
      "metadata": {
        "id": "EnCLKLG9og3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.data import AUTOTUNE\n",
        "from os.path import join as join_path"
      ],
      "outputs": [],
      "metadata": {
        "id": "MdsW27iD28sA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SZ = 200"
      ],
      "outputs": [],
      "metadata": {
        "id": "CNe0BZkHokLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RANDOM_SEED = 42"
      ],
      "outputs": [],
      "metadata": {
        "id": "0FRgMFMDo1UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens"
      ],
      "metadata": {
        "id": "2FiWg76aptvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# represent voxels located in the:\n",
        "# 0: background\n",
        "# 1: RV cavity\n",
        "# 2: myocardium\n",
        "# 3: LV cavity \n",
        "CLASSES_CNT = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "teZ1vFnBo86-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INPUT_CHANNELS = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "yhPLtcgFIBS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATCH_STEP = 18"
      ],
      "outputs": [],
      "metadata": {
        "id": "4AJ4EW5HCRpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SUFIX = '_data'"
      ],
      "outputs": [],
      "metadata": {
        "id": "0jmhXzzrjHUd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_SUFIX = '_mask'"
      ],
      "outputs": [],
      "metadata": {
        "id": "388ZVEbVjKoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CLASS_WEIGHT_FILENAME = 'classes_weight.npy'\n",
        "CLASS_WEIGHT_FILENAME = join_path(*drive_path, CLASS_WEIGHT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PFpk9RQXpLGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data-subgroup"
      ],
      "metadata": {
        "id": "OWKzttYtjp7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "6rKj41ofVL5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "XVALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "0-UDTg4lo7GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "fo7dJMWKjNRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DT_SHUFFLE_SZ = 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lwnnmbtnn3_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PREFETCH_DATA_SZ = AUTOTUNE"
      ],
      "outputs": [],
      "metadata": {
        "id": "XytTiCOEMrPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BASE_DATA_DIR = 'ACDC_2017_dados'\n",
        "\n",
        "RAW_TRAINING_FILENAME = 'training.zip'\n",
        "RAW_TRAINING_DIR = 'raw_train'\n",
        "PATCHES_DIR = 'image_patches'\n",
        "TRAINING_DIR = 'train'\n",
        "X_VAL_DIR = 'validation'\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "RAW_TRAINING_DIR = join_path(BASE_DATA_DIR, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, X_VAL_DIR)\n",
        "TEST_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TEST_DIR)\n",
        "\n",
        "RAW_TRAINING_FILENAME = join_path(*drive_path, RAW_TRAINING_FILENAME)\n",
        "RAW_TRAINING_DIR = join_path(*drive_path, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(*drive_path, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(*drive_path, X_VAL_DIR)\n",
        "TEST_DIR = join_path(*drive_path, TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FypEp4tTqFOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_GLOB_SEARCH = ''.join(['*', IMG_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "VlmtbvhYk-Zh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_GLOB_SEARCH = ''.join(['*', MASK_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPBLY1dCTjwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos"
      ],
      "metadata": {
        "id": "Z5tTzWDkqmFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# MODEL_FILENAME = 'ulas_model'\n",
        "MODEL_FILENAME = 'ulas_model_v2'\n",
        "\n",
        "\n",
        "# MODEL_FILENAME = 'linknet_model'\n",
        "# MODEL_FILENAME = 'unet_model'"
      ],
      "outputs": [],
      "metadata": {
        "id": "RE7z_CNNqoiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_DIR = join_path(*drive_path, MODEL_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QW8kwOYwqsS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquitetura Ulas"
      ],
      "metadata": {
        "id": "2lEQdpd8K_la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "POOL_SIZE = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "nPkeN2YyLCtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas e Funções de perda"
      ],
      "metadata": {
        "id": "M_VUxpZxt5IE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "SMOOTH = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "wpy8ho6IGiTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "FOCAL_LOSS_GAMA = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "d0NCWDkVuDMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento"
      ],
      "metadata": {
        "id": "abjYtJ7zp2Bj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INIT_LEARNING_RATE = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "gPy_ujYcpDiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MIN_LEARNING_RATE = 1e-6"
      ],
      "outputs": [],
      "metadata": {
        "id": "DExT9SdYpNCm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BATCH_SIZE = 16"
      ],
      "outputs": [],
      "metadata": {
        "id": "kAAyIdURprUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INITAL_EPOCH = 7"
      ],
      "outputs": [],
      "metadata": {
        "id": "2MGb3tctlHvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAX_EPOCH = 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "cm_NFCiKSIrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAIN_METRIC = 'dice_metric'"
      ],
      "outputs": [],
      "metadata": {
        "id": "R7LBrU0Ptpw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if MODEL_FILENAME == 'unet_plusplus_model':\n",
        "    EVAL_METRIC = f're_lu_{MAIN_METRIC}'\n",
        "else:\n",
        "    EVAL_METRIC = MAIN_METRIC"
      ],
      "outputs": [],
      "metadata": {
        "id": "gIERQ-Kqtt3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "METRIC_THRESHOLD = .5"
      ],
      "outputs": [],
      "metadata": {
        "id": "y1p09qit9-Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "IDXFT87zPDUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_ROTATION = 90"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPQ6ps85PF76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_HOR_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "yPicNXYUPKVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_VER_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "g3hQd0c_PP7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_WIDTH_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "gwViSbPsPdpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_HEIGHT_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "UtBEysfLPfoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_ZOOM_FACTOR = 10\n",
        "AUG_ZOOM = (10, 16) # x10"
      ],
      "outputs": [],
      "metadata": {
        "id": "qWvTb7owPgaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_FILL_MODE = 'constant'"
      ],
      "outputs": [],
      "metadata": {
        "id": "40y_uDu-PhU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestones do treinamento"
      ],
      "metadata": {
        "id": "A_lgkcSdrq25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "EARLY_STOP_PATIENCE = 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "fp0RTecqsvC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "LR_REDUCER_PATIENCE = 3"
      ],
      "outputs": [],
      "metadata": {
        "id": "__8-O_YPMhMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_FILENAME = join_path(\n",
        "    MODEL_DIR,\n",
        "    f'{MODEL_FILENAME}.h5'\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "asIAvRtHs5Rh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CSV_LOG_FILENAME = join_path(MODEL_DIR, f'{MODEL_FILENAME}_log.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y8OTM6KNs-vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados"
      ],
      "metadata": {
        "id": "MkYM5QDBtPul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_FILENAME = f'{MODEL_FILENAME}_structure.png'\n",
        "PLOT_FILENAME = join_path(MODEL_DIR, PLOT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VAkIzuNPtOzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_WIDTH = 720"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8k9BznKtWcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação das imagens"
      ],
      "metadata": {
        "id": "jRA4xxMDuLRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports desta seção"
      ],
      "metadata": {
        "id": "eLKawJgfvLcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import sleep\n",
        "from numpy import unique\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.image import extract_patches\n",
        "from tensorflow.keras.utils import normalize, to_categorical"
      ],
      "outputs": [],
      "metadata": {
        "id": "6DctGw4bvN7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens originais, .nii.gz"
      ],
      "metadata": {
        "id": "enXqnOMtiIpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "author: Clément Zotti (clement.zotti@usherbrooke.ca)\n",
        "date: April 2017\n",
        "\n",
        "DESCRIPTION :\n",
        "The script provide helpers functions to handle nifti image format:\n",
        "    - load_nii()\n",
        "    - save_nii()\n",
        "\n",
        "to generate metrics for two images:\n",
        "    - metrics()\n",
        "\n",
        "And it is callable from the command line (see below).\n",
        "Each function provided in this script has comments to understand\n",
        "how they works.\n",
        "\n",
        "HOW-TO:\n",
        "\n",
        "This script was tested for python 3.4.\n",
        "\n",
        "First, you need to install the required packages with\n",
        "    pip install -r requirements.txt\n",
        "\n",
        "After the installation, you have two ways of running this script:\n",
        "    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n",
        "    2) python metrics.py ground_truth/ prediction/\n",
        "\n",
        "The first option will print in the console the dice and volume of each class for the given image.\n",
        "The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n",
        "\n",
        "\n",
        "Based on: http://acdc.creatis.insa-lyon.fr\n",
        "\"\"\"\n",
        "#\n",
        "# Utils function to load and save nifti files with the nibabel package\n",
        "#\n",
        "def load_nii(img_path):\n",
        "    \"\"\"\n",
        "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
        "    everyting needed to save another 'nii' or 'nii.gz'\n",
        "    in the same dimensional space, i.e. the affine matrix and the header\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Three element, the first is a numpy array of the image values,\n",
        "    the second is the affine transformation of the image, and the\n",
        "    last one is the header of the image.\n",
        "    \"\"\"\n",
        "    nimg = nib.load(img_path)\n",
        "    return nimg.get_fdata().astype('float32'), nimg.affine, nimg.header\n",
        "\n",
        "def save_nii(img_path, data, affine, header):\n",
        "    \"\"\"\n",
        "    Function to save a 'nii' or 'nii.gz' file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
        "\n",
        "    data: np.array\n",
        "    Numpy array of the image data.\n",
        "\n",
        "    affine: list of list or np.array\n",
        "    The affine transformation to save with the image.\n",
        "\n",
        "    header: nib.Nifti1Header\n",
        "    The header that define everything about the data\n",
        "    (pleasecheck nibabel documentation).\n",
        "    \"\"\"\n",
        "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
        "    nimg.to_filename(img_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fosux3OuQkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localização dos arquivos"
      ],
      "metadata": {
        "id": "ppq0c2DAimvE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def file_paths(base_dir):\n",
        "    c_paths = {\n",
        "        'config': [],\n",
        "        'ground_truth': [],\n",
        "        'images': [],\n",
        "        '4d': []\n",
        "    }\n",
        "\n",
        "    for c_dir, next_dirs, file_names in os.walk(base_dir):\n",
        "        # skip root\n",
        "        if next_dirs:\n",
        "            continue\n",
        "\n",
        "        c_patient = os.path.basename(c_dir)\n",
        "\n",
        "        for f_n in file_names:\n",
        "            f_n = os.path.join(c_dir, f_n)\n",
        "\n",
        "            if f_n.endswith('.cfg'): file_type = 'config'\n",
        "            elif '_gt' in f_n: file_type = 'ground_truth'\n",
        "            elif '_4d' in f_n: file_type = '4d'\n",
        "            else: file_type = 'images'\n",
        "\n",
        "            c_paths[file_type].append(f_n)\n",
        "\n",
        "    for file_type in c_paths.keys():\n",
        "        c_paths[file_type].sort()\n",
        "\n",
        "    return c_paths"
      ],
      "outputs": [],
      "metadata": {
        "id": "XLJTixvmiP5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversões diretas salvas"
      ],
      "metadata": {
        "id": "3XN_in9viXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_data(file_paths, is_training=True):\n",
        "    images_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_data.npy')\n",
        "    gt_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_gt_data.npy')\n",
        "\n",
        "    try:\n",
        "        imgs = np.load(images_filename, allow_pickle=True)\n",
        "        imgs_gt = np.load(gt_filename, allow_pickle=True)\n",
        "\n",
        "        if np.any(imgs) and np.any(imgs_gt):\n",
        "            print('carregado dos arquivos')\n",
        "\n",
        "            return tf.convert_to_tensor(imgs), tf.convert_to_tensor(imgs_gt, dtype=tf.float32)\n",
        "    except:\n",
        "        print('lendo imagens arquivos')\n",
        "        imgs, imgs_gt =  _load_data(file_paths)\n",
        "\n",
        "        # np.save(images_filename, imgs)\n",
        "        # np.save(gt_filename, imgs_gt)\n",
        "\n",
        "        return imgs, imgs_gt\n",
        "\n",
        "def load_classes_weight(labels=None):\n",
        "    return None\n",
        "    try:\n",
        "        weights = np.load(CLASS_WEIGHT_FILENAME, allow_pickle=True)\n",
        "\n",
        "        if np.any(weights):\n",
        "            print('carregado do arquivo')\n",
        "\n",
        "            return weights\n",
        "    except:\n",
        "        print('calculando pesos')\n",
        "        if not np.any(labels):\n",
        "            return None\n",
        "\n",
        "        weights = compute_class_weight(\n",
        "            'balanced',\n",
        "            np.arange(CLASSES_CNT),\n",
        "            tf.reshape(tf.cast(labels, tf.int8), [-1]).numpy()\n",
        "        )\n",
        "\n",
        "        np.save(CLASS_WEIGHT_FILENAME, weights)\n",
        "\n",
        "        return weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZfLGFpW2iV19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento das imagens originais"
      ],
      "metadata": {
        "id": "gEiOw6_JitX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_data(file_paths):\n",
        "    images, ground_truth = [], []\n",
        "    cnt = 1\n",
        "\n",
        "    for c_img, c_ground_truth in zip(file_paths['images'], file_paths['ground_truth']):\n",
        "        print(f'processing {cnt}...')\n",
        "\n",
        "        # we load 3D training image\n",
        "        training_image, _, _ = load_nii(c_img)\n",
        "        # we load 3D training mask (shape=(512,512,129))\n",
        "        train_ground_truth, _, _ = load_nii(c_ground_truth)\n",
        "\n",
        "        for k in range(min(train_ground_truth.shape[-1], training_image.shape[-1])):\n",
        "            #axial cuts are made along the z axis with undersampling\n",
        "            gt_2d = np.array(train_ground_truth[::, ::, k])\n",
        "\n",
        "            # invalid ground truth\n",
        "            if len(np.unique(gt_2d)) == 1:\n",
        "                continue\n",
        "\n",
        "            image_patches = _extract_patches(\n",
        "                _pre_process_img(np.array(training_image[::, ::, k]))\n",
        "            )\n",
        "            gt_patches = _extract_patches(gt_2d)\n",
        "\n",
        "            if (tf.size(images) == 0).numpy():\n",
        "                images = image_patches\n",
        "            else:\n",
        "                images = tf.concat((images, image_patches), axis=0)\n",
        "\n",
        "            if (tf.size(ground_truth) == 0).numpy():\n",
        "                ground_truth = gt_patches\n",
        "            else:\n",
        "                ground_truth = tf.concat((ground_truth, gt_patches), axis=0)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "    return images, ground_truth\n",
        "\n",
        "def _extract_patches(image_2d):\n",
        "    image_2d = tf.expand_dims(tf.expand_dims(image_2d, axis=-1), axis=0)\n",
        "\n",
        "    if image_2d.shape[1] < IMG_SZ or image_2d.shape[2] < IMG_SZ:\n",
        "        return tf.image.resize(\n",
        "            image_2d, (IMG_SZ, IMG_SZ), method='nearest'\n",
        "        )\n",
        "\n",
        "    image_patches = extract_patches(\n",
        "        image_2d,\n",
        "        sizes=[1, IMG_SZ, IMG_SZ, 1],\n",
        "        strides=[1, PATCH_STEP, PATCH_STEP, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    return tf.reshape(\n",
        "        image_patches,\n",
        "        [image_patches.shape[1] * image_patches.shape[2], IMG_SZ, IMG_SZ, 1]\n",
        "    )\n",
        "\n",
        "# Based on: https://github.com/MinaJf/FU-net/blob/HEAD/image_loder.py\n",
        "def _pre_process_img(img):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # standardization (zero mean)\n",
        "    img -= tf.math.reduce_mean(img)\n",
        "    img /= tf.math.reduce_std(img)\n",
        "\n",
        "    # normalize between [0, 1]\n",
        "    img -= tf.math.reduce_min(img)\n",
        "    img /= tf.math.reduce_max(img)\n",
        "\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "7rDOEKiCvsVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_patches(patches, base_dir, is_label=False):\n",
        "    for ind, img in enumerate(patches, start=1):\n",
        "        img_name = f'{ind}{MASK_SUFIX if is_label else IMG_SUFIX}'\n",
        "        img_path = os.path.join(base_dir, img_name)\n",
        "\n",
        "        np.save(img_path, img)\n",
        "        # while True:\n",
        "        #     print(f'\\t a salvar...')\n",
        "        #     sleep(2)\n",
        "\n",
        "        #     if os.path.exists(img_path): break\n",
        "            \n",
        "        print(f'saved {img_path}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y4fDYPWhh_4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação dos dados"
      ],
      "metadata": {
        "id": "Al2EYzA3kFup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.utils import to_categorical, Sequence\n",
        "from numpy import load\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import skimage.transform as img_transform\n",
        "from gc import collect as gc_collector"
      ],
      "outputs": [],
      "metadata": {
        "id": "vyBVdSOHkKfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def check_cnt(main_path):\n",
        "    img_filenames = glob(os.path.join(main_path, IMG_GLOB_SEARCH))\n",
        "    mask_filenames = glob(os.path.join(main_path, MASK_GLOB_SEARCH))\n",
        "\n",
        "    img_cnt = len(img_filenames)\n",
        "    mask_cnt = len(mask_filenames)\n",
        "\n",
        "    print('img_cnt', img_cnt)\n",
        "    print('mask_cnt', mask_cnt)\n",
        "\n",
        "    return (\n",
        "        img_cnt if img_cnt == mask_cnt else 0,\n",
        "        tf.convert_to_tensor(img_filenames),\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "0JpDzETkm9wQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_images(batch_paths):\n",
        "    def _load_img(img_path):\n",
        "        img_path = img_path.decode()\n",
        "\n",
        "        image = load(img_path, allow_pickle=True)\n",
        "\n",
        "        mask_path = img_path.replace(IMG_SUFIX, MASK_SUFIX)\n",
        "        \n",
        "        mask = load(mask_path, allow_pickle=True)\n",
        "\n",
        "        mask = mask.astype('int8')\n",
        "      \n",
        "        return image, mask\n",
        "\n",
        "    return _load_img(batch_paths)\n",
        "\n",
        "    img_batch, mask_batch = [], []\n",
        "\n",
        "    for img_path in batch_paths:\n",
        "        image, mask = _load_img(img_path)\n",
        "        img_batch.append(image)\n",
        "        mask_batch.append(mask)\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "6uHK3-WqkNMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def ensure_shape(img_batch, mask_batch):\n",
        "    img_batch = tf.convert_to_tensor(img_batch)\n",
        "    mask_batch = tf.convert_to_tensor(mask_batch)\n",
        "\n",
        "    # img_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "    # mask_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "\n",
        "    img_batch.set_shape((IMG_SZ, IMG_SZ, 1))\n",
        "    mask_batch.set_shape((IMG_SZ, IMG_SZ, 1))\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "sLLRl-FPkZal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def pre_processing(img_batch, mask_batch):\n",
        "    # if not mask_batch.shape:\n",
        "    #     mask_batch.set_shape(img_batch.shape)\n",
        "\n",
        "    mask_batch = tf.one_hot(mask_batch, CLASSES_CNT)\n",
        "    mask_batch = tf.squeeze(mask_batch)\n",
        "    # mask_batch = tf.squeeze(mask_batch, axis=3)\n",
        "\n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "XZIfFEoArrIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def data_augmentation(img_batch, mask_batch):\n",
        "    from random import choice, randint\n",
        "\n",
        "    yes_no = [True, False]\n",
        "\n",
        "    def _augmentation(combined_batches):\n",
        "        c_img, c_mask = combined_batches\n",
        "\n",
        "        # horizontal_flip=True,\n",
        "        if choice(yes_no):\n",
        "            c_img = tf.image.flip_left_right(c_img)\n",
        "            c_mask = tf.image.flip_left_right(c_mask)\n",
        "\n",
        "        # vertical_flip=True,\n",
        "        if choice(yes_no):\n",
        "            c_img = tf.image.flip_up_down(c_img)\n",
        "            c_mask = tf.image.flip_up_down(c_mask)\n",
        "\n",
        "        # rotation_range=90\n",
        "        if choice(yes_no):\n",
        "            angle = randint(-AUG_ROTATION // 2, AUG_ROTATION // 2)\n",
        "\n",
        "            c_img = img_transform.rotate(c_img.numpy(), angle, mode=AUG_FILL_MODE)\n",
        "            c_mask = img_transform.rotate(c_mask.numpy(), angle, mode=AUG_FILL_MODE)\n",
        "\n",
        "        # zoom_range=AUG_ZOOM\n",
        "        # width_shift_range=.4\n",
        "        # height_shift_range=.4\n",
        "        \n",
        "        return tf.convert_to_tensor(c_img), tf.convert_to_tensor(c_mask)\n",
        "\n",
        "    gc_collector()\n",
        "    return _augmentation((img_batch, mask_batch))\n",
        "\n",
        "    # return tf.map_fn(\n",
        "    #     _augmentation,\n",
        "    #     (img_batch, mask_batch),\n",
        "    #     dtype=(img_batch.dtype, mask_batch.dtype)\n",
        "    # )"
      ],
      "outputs": [],
      "metadata": {
        "id": "7SIIEIy301ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_dataset(main_path, shuffle_sz=False, should_data_aug=False):\n",
        "    dataset = Dataset.list_files(os.path.join(main_path, IMG_GLOB_SEARCH), shuffle=True, seed=RANDOM_SEED)\n",
        "\n",
        "    # dataset = dataset.repeat()\n",
        "\n",
        "    if shuffle_sz:\n",
        "        dataset = dataset.shuffle(\n",
        "            buffer_size=shuffle_sz,\n",
        "            reshuffle_each_iteration=True\n",
        "        )\n",
        "\n",
        "    dataset = dataset.map(\n",
        "        lambda img_path: tf.numpy_function(_load_images, [img_path], (tf.float32, tf.int8)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    dataset = dataset.map(ensure_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.map(pre_processing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if should_data_aug:\n",
        "        dataset = dataset.map(\n",
        "            # data_augmentation,\n",
        "            lambda img, mask: tf.numpy_function(data_augmentation, [img, mask], (tf.float32, tf.int8)),\n",
        "            num_parallel_calls=tf.data.AUTOTUNE\n",
        "        )\n",
        "\n",
        "    # dataset = dataset.cache()\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "DI6iSPxOkcdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class CustomGenerator(Sequence):\n",
        "    def __init__(self, name, x_filenames, can_shuffle=False, should_apply_data_aug=False, batch_sz=BATCH_SIZE):\n",
        "        self.name = name\n",
        "        \n",
        "        self.raw_data = self._raw_data(x_filenames, can_shuffle)\n",
        "        self.apply_data_aug = should_apply_data_aug\n",
        "        self.batch_sz = batch_sz\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.can_shuffle:\n",
        "            self.raw_data = tf.random.shuffle(self.raw_data)\n",
        "    \n",
        "    def __getitem__(self, c_begin):\n",
        "        tf.print(f'[{self.name}] getting batch #{c_begin}')\n",
        "        c_being = tf.constant([c_begin * self.batch_sz])\n",
        "        c_batch_sz = tf.constant([self.batch_sz])\n",
        "\n",
        "        c_batch = tf.slice(self.raw_data, c_being, c_batch_sz)\n",
        "\n",
        "        data, mask = self._getbatch(c_batch)\n",
        "\n",
        "        tf.print(f'\\tdata: {data.dtype} - {data.shape}')\n",
        "        tf.print(f'\\tmask: {mask.dtype} - {mask.shape}')\n",
        "\n",
        "        return data, mask\n",
        "    \n",
        "    def __len__(self):\n",
        "        return tf.size(self.raw_data) // self.batch_sz\n",
        "\n",
        "    def _raw_data(self, x_filenames, can_shuffle):\n",
        "        if can_shuffle:\n",
        "            x_filenames = tf.random.shuffle(x_filenames)\n",
        "\n",
        "        return x_filenames\n",
        "\n",
        "    def _getbatch(self, batch_paths):\n",
        "        data_batch, mask_batch = self._load_files(batch_paths)\n",
        "\n",
        "        data_batch, mask_batch = self._pre_processing(data_batch, mask_batch)\n",
        "\n",
        "        if self.apply_data_aug:\n",
        "            data_batch, mask_batch = self._data_augmentation(data_batch, mask_batch)\n",
        "\n",
        "        mask_batch = tf.cast(mask_batch, tf.int8)\n",
        "\n",
        "        return data_batch, mask_batch\n",
        "    \n",
        "    def _load_files(self, batch_paths):\n",
        "        tf.print(f'\\tloading... {batch_paths}')\n",
        "        img_batch, mask_batch = [], []\n",
        "\n",
        "        for img_path in batch_paths:\n",
        "            image, mask = self._load_img(img_path)\n",
        "            img_batch.append(image)\n",
        "            mask_batch.append(mask)\n",
        "\n",
        "        return tf.convert_to_tensor(img_batch), tf.convert_to_tensor(mask_batch)\n",
        "\n",
        "    def _load_img(self, img_path):\n",
        "        # tf.print(f'\\tloading... {img_path}')\n",
        "        img_path = img_path.numpy().decode()\n",
        "\n",
        "        image = load(img_path, allow_pickle=True)\n",
        "\n",
        "        mask_path = img_path.replace(IMG_SUFIX, MASK_SUFIX)\n",
        "        \n",
        "        mask = load(mask_path, allow_pickle=True)\n",
        "\n",
        "        mask = mask.astype('int8')\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def _pre_processing(self, img_batch, mask_batch):\n",
        "        tf.print('\\t_pre_processing...')\n",
        "        # if not mask_batch.shape:\n",
        "        #     mask_batch.set_shape(img_batch.shape)\n",
        "\n",
        "        mask_batch = tf.one_hot(mask_batch, CLASSES_CNT)\n",
        "        mask_batch = tf.squeeze(mask_batch)\n",
        "        # mask_batch = tf.squeeze(mask_batch, axis=3)\n",
        "\n",
        "        return img_batch, mask_batch\n",
        "    \n",
        "    def _data_augmentation(self, img_batch, mask_batch):\n",
        "        tf.print('\\t_data_augmentation...')\n",
        "        gc_collector()\n",
        "\n",
        "        return tf.map_fn(\n",
        "            self._augmentation,\n",
        "            (img_batch, mask_batch),\n",
        "            dtype=(img_batch.dtype, mask_batch.dtype)\n",
        "        )\n",
        "\n",
        "    def _augmentation(self, combined_batches):\n",
        "        c_img, c_mask = combined_batches\n",
        "\n",
        "        # horizontal_flip=True,\n",
        "        if tf.random.uniform(()) > .5:\n",
        "            c_img = tf.image.flip_left_right(c_img)\n",
        "            c_mask = tf.image.flip_left_right(c_mask)\n",
        "\n",
        "        # vertical_flip=True,\n",
        "        if tf.random.uniform(()) > .5:\n",
        "            c_img = tf.image.flip_up_down(c_img)\n",
        "            c_mask = tf.image.flip_up_down(c_mask)\n",
        "\n",
        "        # rotation_range=90\n",
        "        if tf.random.uniform(()) > .5:\n",
        "            angle = tf.random.uniform((), minval=-AUG_ROTATION // 2, maxval=AUG_ROTATION // 2, dtype=tf.int32).numpy()\n",
        "\n",
        "            c_img = img_transform.rotate(c_img.numpy(), angle, mode=AUG_FILL_MODE)\n",
        "            c_mask = img_transform.rotate(c_mask.numpy(), angle, mode=AUG_FILL_MODE)\n",
        "\n",
        "        return tf.convert_to_tensor(c_img), tf.convert_to_tensor(c_mask)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "71IXnhlDtmpx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def display_sample(display_list, to_save=False):\n",
        "    \"\"\"Show side-by-side an input image,\n",
        "    the ground truth and the prediction.\n",
        "    \"\"\"\n",
        "    plt.figure(dpi=180)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    if len(display_list) == 3:\n",
        "        gt = display_list[1]\n",
        "        pred = tf.cast(display_list[2], tf.int8)\n",
        "\n",
        "        # gt = tf.image.resize(gt, (50, 50), 'nearest')\n",
        "        # pred = tf.image.resize(pred, (50, 50), 'nearest')\n",
        "        \n",
        "        equal = gt * pred\n",
        "        \n",
        "        display_list.append(equal)\n",
        "        display_list.append(gt - equal)\n",
        "        display_list.append(pred - equal)\n",
        "\n",
        "    settings = [\n",
        "        { # 0\n",
        "            'title': 'Input Image',\n",
        "            'pre_processing': lambda x: tf.squeeze(x, axis=2),\n",
        "        },\n",
        "        { # 1\n",
        "            'title': 'Ground Truth',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 2\n",
        "            'title': 'Prediction',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 3\n",
        "            'title': 'Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 4\n",
        "            'title': 'G.T. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 5\n",
        "            'title': 'Pred. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    for ind, image in enumerate(display_list):\n",
        "        print()\n",
        "        print(image.shape)\n",
        "        plt.subplot(1, len(display_list), ind + 1)\n",
        "        plt.title(settings[ind]['title'])\n",
        "        plt.imshow(settings[ind]['pre_processing'](image), cmap='hot')\n",
        "        plt.axis('off')\n",
        "\n",
        "    if to_save and len(display_list) == len(settings):\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.svg'), dpi=300)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.png'), dpi=300)\n",
        "\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nOYPJSVWwGnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo em mémoria"
      ],
      "metadata": {
        "id": "hcEtyDUbOIcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "m_mBzEfeOOaj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZFteRO3KOQfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Based on: https://github.com/mjbhobe/dl-tensorflow-keras/blob/master/kr_helper_funcs.py\n",
        "def save_model(model, file_name, save_dir):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"\n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(f'Não foi possível criar o repositório \"{save_dir}\", para salvar o modelo. Terminando a execução!')\n",
        "            raise err\n",
        "\n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (file_name + '.h5'))\n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save(\n",
        "        h5_file_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "        save_traces=True,\n",
        "    )\n",
        "\n",
        "    print(f'Modelo salvo nos arquivos: \"{json_file_path}\" e \"{h5_file_path}\" ')\n",
        "\n",
        "def load_model(file_name, load_dir):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "\n",
        "        print(f'Modelo construído a partir dos arquivos: \"{json_file_path}\" e \"{h5_file_path}\"')\n",
        "\n",
        "    else:\n",
        "        print(\n",
        "            f'Arquivos não encontrados: \"{(file_name + \".json\")}\" e \"{(file_name + \".h5\")}\", na pasta \"{load_dir}\"'\n",
        "        )\n",
        "\n",
        "    return loaded_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "_9b0an3PObPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas manuais"
      ],
      "metadata": {
        "id": "UlEma1WCF49k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "cHLZZaBVF9vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "HpUXCOL2GABF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def inter_union_sum(y_true, y_pred):\n",
        "    # W,H axes of each image\n",
        "    axes = (1,2)\n",
        "    \n",
        "    intersection = K.sum(K.abs(y_pred * y_true), axis=axes)\n",
        "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection\n",
        "\n",
        "    return intersection, union, mask_sum"
      ],
      "outputs": [],
      "metadata": {
        "id": "RMc9OGrhGeoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def dice_metric(y_true, y_pred):\n",
        "    # 2*|A & B| / (|A| + |B|)\n",
        "    intersection, _, mask_sum = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    dice = 2 * (intersection + SMOOTH)/(mask_sum + SMOOTH)\n",
        "\n",
        "    return K.mean(dice)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F82GF0c8HNye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def jaccard_metric(y_true, y_pred):\n",
        "    # |A & B| / (| A U B|)\n",
        "    intersection, union, _ = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    jaccard = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "\n",
        "    return K.mean(jaccard)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GPs64AkvH3S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquiteturas conhecidas"
      ],
      "metadata": {
        "id": "w7JKL6lA3CmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "5PSNvgqf3F2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from segmentation_models import Linknet, Unet, set_framework"
      ],
      "outputs": [],
      "metadata": {
        "id": "kvk8GdP63HfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2332399f-d4d6-4ffd-84ba-a2cb3d929d21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "set_framework('tf.keras')"
      ],
      "outputs": [],
      "metadata": {
        "id": "IURIWD4j7OBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_linknet_model(num_classes=1, backbone='resnet34'):\n",
        "    return Linknet(\n",
        "        backbone,\n",
        "        encoder_weights='imagenet',\n",
        "        classes=num_classes,\n",
        "        activation='softmax' if num_classes > 1 else 'sigmoid'\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "DY6rzAeE3IB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_unet_model(num_classes=1, backbone='resnet34'):\n",
        "    return Unet(\n",
        "        backbone,\n",
        "        encoder_weights='imagenet',\n",
        "        classes=num_classes,\n",
        "        activation='softmax' if num_classes > 1 else 'sigmoid'\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "vCflh1cb4HGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura proposto por Ulas"
      ],
      "metadata": {
        "id": "MP_30iwQG5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "zYDwVYDzHXos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import swish\n",
        "from tensorflow.keras.layers import (Activation, AveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D,\n",
        "                                     UpSampling2D, concatenate)\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNa9WsFXHDqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_item_dense_layer(inputs, filters, kernel):\n",
        "    conv = Conv2D(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel,\n",
        "        padding='same',\n",
        "        use_bias=False\n",
        "    )(inputs)\n",
        "    bn = BatchNormalization()(conv)\n",
        "    act = Activation(swish)(bn)\n",
        "\n",
        "    return act"
      ],
      "outputs": [],
      "metadata": {
        "id": "zh84s9GzHl_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_dense_layer(input, conv_confs):\n",
        "    fst = _get_ulas_item_dense_layer(input, *conv_confs[0])\n",
        "    snd = _get_ulas_item_dense_layer(concatenate([input, fst]), *conv_confs[1])\n",
        "    trd = _get_ulas_item_dense_layer(concatenate([input, fst, snd]), *conv_confs[2])\n",
        "    frt = _get_ulas_item_dense_layer(concatenate([input, fst, snd, trd]), *conv_confs[3])\n",
        "\n",
        "    return frt"
      ],
      "outputs": [],
      "metadata": {
        "id": "rVOVnG5QHoWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_ulas_model(num_classes=1, pool_size=POOL_SIZE):\n",
        "    input = Input(\n",
        "        shape=(IMG_SZ, IMG_SZ, INPUT_CHANNELS),\n",
        "        dtype='float32'\n",
        "    )\n",
        "\n",
        "    # 1º parte do encoder\n",
        "    dense1 = _get_ulas_dense_layer(\n",
        "        input,\n",
        "        [\n",
        "            (160, (3, 7)),\n",
        "            (112, (3, 7)),\n",
        "            (144, (9, 7)),\n",
        "            (80, (3, 11)),\n",
        "        ]\n",
        "    )\n",
        "    trans1 = MaxPooling2D(pool_size=(pool_size, pool_size))(dense1)\n",
        "\n",
        "    # 2º parte do encoder\n",
        "    dense2 = _get_ulas_dense_layer(\n",
        "        trans1, \n",
        "        [\n",
        "            (144, (3, 5)),\n",
        "            (176, (7, 1)),\n",
        "            (144, (9, 9)),\n",
        "            (96, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "    trans2 = AveragePooling2D(pool_size=(pool_size, pool_size))(dense2)\n",
        "\n",
        "    # 1º parte da ponte\n",
        "    dense3 = _get_ulas_dense_layer(\n",
        "        trans2, \n",
        "        [\n",
        "            (176, (1, 1)),\n",
        "            (128, (3, 5)),\n",
        "            (208, (7, 7)),\n",
        "            (212, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte da ponte\n",
        "    dense4 = _get_ulas_dense_layer(\n",
        "        dense3, \n",
        "        [\n",
        "            (64, (1, 7)),\n",
        "            (208, (3, 5)),\n",
        "            (64, (9, 5)),\n",
        "            (208, (7, 9)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 1º parte do decoder\n",
        "    trans3 = UpSampling2D(size=(pool_size, pool_size))(dense4)\n",
        "    dense5 = _get_ulas_dense_layer(\n",
        "        trans3, \n",
        "        [\n",
        "            (208, (5, 7)),\n",
        "            (64, (3, 5)),\n",
        "            (96, (11, 11)),\n",
        "            (112, (7, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte do decoder\n",
        "    trans4 = UpSampling2D(size=(pool_size, pool_size))(dense5)\n",
        "    dense6 = _get_ulas_dense_layer(\n",
        "        trans4, \n",
        "        [\n",
        "            (128, (5, 5)),\n",
        "            (80, (11, 7)),\n",
        "            (64, (1, 1)),\n",
        "            (16, (3, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    final = Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(3, 7),\n",
        "        padding='same',\n",
        "        activation='softmax'\n",
        "    )(dense6)\n",
        "\n",
        "    model = Model(inputs=input, outputs=final)\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "u4qjBkYZHid4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_ulas_model_v2(num_classes=1, pool_size=POOL_SIZE):\n",
        "    return get_ulas_model(num_classes, pool_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "b14PiX4ldFO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências de Treinamento\n",
        "\n"
      ],
      "metadata": {
        "id": "iIDrnFqqI8yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "TKGfQssKJOes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from segmentation_models.losses import DiceLoss, CategoricalFocalLoss\n",
        "from segmentation_models.metrics import IOUScore, FScore"
      ],
      "outputs": [],
      "metadata": {
        "id": "3-8d_PzFJQ_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=INIT_LEARNING_RATE\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9KNRADbkJjxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=AUG_ROTATION,\n",
        "    horizontal_flip=AUG_W_HOR_FLIP,\n",
        "    vertical_flip=AUG_W_VER_FLIP,\n",
        "    width_shift_range=AUG_WIDTH_RNG,\n",
        "    height_shift_range=AUG_HEIGHT_RNG,\n",
        "    zoom_range=AUG_ZOOM,\n",
        "\tfill_mode=AUG_FILL_MODE\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "--5ZhnlqO7fM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def loss_func(class_weights):\n",
        "    dice_loss = DiceLoss(class_weights=class_weights, smooth=SMOOTH)\n",
        "    focal_loss = CategoricalFocalLoss(gamma=FOCAL_LOSS_GAMA)\n",
        "\n",
        "    return dice_loss + focal_loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "bUKz7pdSFM2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def metric_func(class_weights):\n",
        "    return [\n",
        "        dice_metric,\n",
        "        jaccard_metric,\n",
        "        'accuracy',\n",
        "        'categorical_accuracy',\n",
        "        MeanIoU(num_classes=CLASSES_CNT),\n",
        "        IOUScore(class_weights=class_weights, smooth=SMOOTH, threshold=METRIC_THRESHOLD),\n",
        "        FScore(smooth=SMOOTH, threshold=METRIC_THRESHOLD)\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "rHnUtiZKHG9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def compile_model(model, class_weights=[]):\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        # 'categorical_crossentropy' | 'sparse_categorical_crossentropy'\n",
        "        # https://keras.io/api/losses/probabilistic_losses/\n",
        "        # loss='categorical_crossentropy',\n",
        "        loss=loss_func(class_weights),\n",
        "        # https://keras.io/api/metrics/\n",
        "        metrics=metric_func(class_weights),\n",
        "        run_eagerly=True\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tFE1qbESJpsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "kXTmW4Fc0RGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epoch_milestone = ModelCheckpoint(\n",
        "    STEPS_FILENAME,\n",
        "    monitor=f'val_{EVAL_METRIC}',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xm2EhKXtLS5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOP_PATIENCE,\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "p29VDRt5LTvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "csv_logger = CSVLogger(\n",
        "    CSV_LOG_FILENAME,\n",
        "    separator=';',\n",
        "    append=True,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNCOR_CDLUwg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=LR_REDUCER_PATIENCE,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    factor=1e-1,\n",
        "    verbose=1\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ea-WROIfMSIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "callbacks = [\n",
        "    epoch_milestone,\n",
        "    early_stop,\n",
        "    csv_logger,\n",
        "    lr_reducer,\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ec8Tejy7NAgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando dados\n",
        "\n"
      ],
      "metadata": {
        "id": "eM2eHxDXYaBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "2vWJJxjQsFHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_cnt, train_img_filenames = check_cnt(TRAINING_DIR)\n",
        "train_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27wkIDcPlIvk",
        "outputId": "224b0a55-6918-4cff-b168-73c341d76ba3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_cnt, xval_img_filenames = check_cnt(X_VAL_DIR)\n",
        "xval_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9dNLmoTnccA",
        "outputId": "5eea66ec-4779-43eb-cf49-eeed0ef5a55c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_cnt, test_img_filenames = check_cnt(TEST_DIR)\n",
        "test_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xmGpodMnbjK",
        "outputId": "b58107e8-f16b-404c-f4e6-fb8fcfad6926"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "there_are_preload_data = all([train_cnt, test_cnt, xval_cnt])\n",
        "there_are_preload_data"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGw8uGkNoD6m",
        "outputId": "cc9bc8e9-0763-461f-ec50-ceb429ab120e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedimentos na ausência de dados"
      ],
      "metadata": {
        "id": "ae61zcz2n47-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    training_paths = file_paths(RAW_TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "U97IDRZ4odfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    raw_train_data, raw_train_labels = load_data(training_paths)\n",
        "\n",
        "    print(f'raw_train_data: {raw_train_data.shape}\\n\\t{raw_train_data.dtype}')\n",
        "    print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "DdNcrIy3opZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    classes_weight = load_classes_weight(raw_train_labels)\n",
        "else:\n",
        "    classes_weight = load_classes_weight()\n",
        "\n",
        "print(f'classes_weight:\\n{classes_weight}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm2tBF0Zoq9Y",
        "outputId": "90b1d3ef-a392-4fc6-f498-189f4d441303"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "        raw_train_data.numpy(), raw_train_labels.numpy(),\n",
        "        test_size=VALIDATION_PROPORTION,\n",
        "        random_state=RANDOM_SEED\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "qrlPUllpotTU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_data, xval_data, train_labels, xval_labels = train_test_split(\n",
        "        train_data, train_labels,\n",
        "        test_size=XVALIDATION_PROPORTION,\n",
        "        random_state=RANDOM_SEED\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "89IGWQwKowno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    print(f'train_data: {train_data.shape} - {train_data.dtype}')\n",
        "    print(f'train_labels: {train_labels.shape} - {train_labels.dtype}')\n",
        "    \n",
        "    print(f'xval_data: {xval_data.shape} - {xval_data.dtype}')\n",
        "    print(f'xval_labels: {xval_labels.shape} - {xval_labels.dtype}')\n",
        "\n",
        "    print(f'test_data: {test_data.shape} - {test_data.dtype}')\n",
        "    print(f'test_labels: {test_labels.shape} - {test_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "j6K6x0hdoxpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(train_labels, TRAINING_DIR, is_label=True)\n",
        "    save_patches(train_data, TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "X6hErjD7oxUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(xval_labels, X_VAL_DIR, is_label=True)\n",
        "    save_patches(xval_data, X_VAL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FXlAJCwI0NfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(test_labels, TEST_DIR, is_label=True)\n",
        "    save_patches(test_data, TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6ofGQvPJ0OOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    del training_paths\n",
        "\n",
        "    del train_data\n",
        "    del train_labels\n",
        "    \n",
        "    del xval_data\n",
        "    del xval_labels\n",
        "    \n",
        "    del test_data\n",
        "    del test_labels"
      ],
      "outputs": [],
      "metadata": {
        "id": "EbamHiCooxAj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    # train_cnt = check_cnt(TRAINING_DIR)\n",
        "    del train_cnt\n",
        "\n",
        "    # xval_cnt = check_cnt(X_VAL_DIR)\n",
        "    del xval_cnt\n",
        "\n",
        "    # test_cnt = check_cnt(TEST_DIR)\n",
        "    del test_cnt"
      ],
      "outputs": [],
      "metadata": {
        "id": "QVzsy8AQCqsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_gen = CustomGenerator('train', train_img_filenames, True, True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "17d2Q8fyw6Hi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_gen = CustomGenerator('xval', xval_img_filenames)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zZTOFkSq9qCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_gen = CustomGenerator('test', test_img_filenames)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4WCJxAWO-mGz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# with tf.device('/cpu:0'):\n",
        "#     train_dataset = get_dataset(TRAINING_DIR, DT_SHUFFLE_SZ, should_data_aug=True)\n",
        "\n",
        "# train_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "2XyC1fQoYmpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# with tf.device('/cpu:0'):\n",
        "#     xval_dataset = get_dataset(X_VAL_DIR)\n",
        "\n",
        "# xval_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "C445gwTDJ1Dx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# with tf.device('/cpu:0'):\n",
        "#     test_dataset = get_dataset(TEST_DIR)\n",
        "\n",
        "# test_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "6RejhvbCJtzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualização teste"
      ],
      "metadata": {
        "id": "X4Pej9qVUj_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "dGKB02ykFt9Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(train_gen) - 1)\n",
        "\n",
        "# img_batch, mask_batch = train_gen.__getitem__(r_ind)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ux8r0iPgCz26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(img_batch) - 1)\n",
        "\n",
        "# sample_image, sample_mask = img_batch[r_ind], mask_batch[r_ind]\n",
        "\n",
        "# print('image', sample_image.dtype, sample_image.shape)\n",
        "# print('mask', sample_mask.dtype, sample_mask.shape)\n",
        "\n",
        "# display_sample([sample_image, sample_mask])"
      ],
      "outputs": [],
      "metadata": {
        "id": "dQo_5QgrwSi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando model"
      ],
      "metadata": {
        "id": "hRDKvbFVwLL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "t1LhMMmt-xNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "euPOixtlyVql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "get_model = f'get_{MODEL_FILENAME}'"
      ],
      "outputs": [],
      "metadata": {
        "id": "PGqgBSc_yXWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "clear_session()"
      ],
      "outputs": [],
      "metadata": {
        "id": "HVxPNvJSyZAA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = load_model(MODEL_FILENAME, MODEL_DIR) or eval(get_model)(CLASSES_CNT)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hK-2y3zpyanu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0683f55e-6c4e-44e9-cae5-225dd7fab170"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = compile_model(model, classes_weight)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0_26VypCygR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gHZNGULAybLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5frUAbo7yinL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3de23f7-8eed-4f26-e625-e67b9daf353f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    to_file=PLOT_FILENAME,\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=True,\n",
        "    dpi=120,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fRnLBHq0ykSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bedc98b-68ab-4d54-b0f6-a1761fc43223"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização prévia"
      ],
      "metadata": {
        "id": "NHNgrwTVUFzc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "cx1lZwgZUKNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i_ooPSRWULIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35a5131-ddbf-46ec-8339-1d5bbe32c540"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(train_gen) - 1)\n",
        "\n",
        "# img_batch, mask_batch = train_gen.__getitem__(r_ind)"
      ],
      "outputs": [],
      "metadata": {
        "id": "IaVstKaQC_Yu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# r_ind = randint(0, len(img_batch) - 1)\n",
        "\n",
        "# sample_image, sample_mask = img_batch[r_ind], mask_batch[r_ind]\n",
        "\n",
        "# predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "# print('image', sample_image.dtype, sample_image.shape)\n",
        "# print('mask', sample_mask.dtype, sample_mask.shape)\n",
        "# print('pred', predict_img.dtype, predict_img.shape)\n",
        "\n",
        "# display_sample([sample_image, sample_mask, predict_img[0]])"
      ],
      "outputs": [],
      "metadata": {
        "id": "2Bw5FogZCw_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "s1agFI3Xyrws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_PER_EPOCH = len(train_gen)\n",
        "STEPS_PER_EPOCH"
      ],
      "outputs": [],
      "metadata": {
        "id": "oQSEOwFJBgeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9670e8ad-99db-46bb-8aea-c793fa91e761"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_STEPS = len(xval_gen)\n",
        "VALIDATION_STEPS "
      ],
      "outputs": [],
      "metadata": {
        "id": "-_TczQjUCDyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1851fb1-a145-40a8-90f3-d8a12600566a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results = model.fit(\n",
        "    # x=aug.flow(train_data, train_labels, batch_size=BATCH_SIZE, seed=RANDOM_SEED),\n",
        "    # train_dataset,\n",
        "    train_gen,\n",
        "    initial_epoch=INITAL_EPOCH,\n",
        "    epochs=MAX_EPOCH,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    # validation_data=(xval_data, xval_labels),\n",
        "    # validation_data=xval_dataset,\n",
        "    validation_data=xval_gen,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OLvwUI35y2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4fa7fe-ead9-4068-eb00-701f3987b1c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mMuC0wdQy4W2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(results.history)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QF7moJWny6cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização final"
      ],
      "metadata": {
        "id": "mZjKdfiev5pT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "MZGDnqMdwCW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "60PKi14rwFbp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for image, mask in test_dataset.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "\n",
        "display_sample([sample_image[0], sample_mask[0], predict_img[0]], to_save=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4QKo8VcjwX7y"
      }
    }
  ]
}