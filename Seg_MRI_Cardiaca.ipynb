{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Seg_MRI_Cardiaca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HC4K3T4SmEf_",
        "eKFfei90mcAJ",
        "jRA4xxMDuLRG",
        "bBnxc1TaUIsT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentação de MRI Cardíacas**\n",
        "\n"
      ],
      "metadata": {
        "id": "HC4K3T4SmEf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "eKFfei90mcAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas"
      ],
      "metadata": {
        "id": "z14WjMKNmnIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "!pip install scikit-learn==0.24.2\n",
        "!pip install focal-loss==0.0.7\n",
        "\n",
        "!pip install nibabel==3.2.1\n",
        "!pip install MedPy==0.4.0\n",
        "\n",
        "!pip install matplotlib==3.2.2"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfB9dnKSl-VP",
        "outputId": "93c0192c-6235-4e19-8e48-708a4dabe813"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acesso à arquivos do Gdrive"
      ],
      "metadata": {
        "id": "UzHCSwCdnIHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = [\n",
        "    '/content/drive',\n",
        "    'My Drive/Colab Notebooks/data'\n",
        "]\n",
        "\n",
        "drive.mount(drive_path[0], force_remount=True)\n",
        "os.chdir('/'.join(drive_path))\n",
        "sys.path.append('/'.join(drive_path))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQl43uvenSLS",
        "outputId": "10294b54-9272-4bef-f1f7-a211d12a9630"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualização da GPU disponibilizada"
      ],
      "metadata": {
        "id": "9VAnelmOnebU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TmRxKiCnnCr",
        "outputId": "ee42ee78-b263-45ad-e678-edf40d530cd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizando a quantidade de GPUs detectadas"
      ],
      "metadata": {
        "id": "9HRMYmjznryn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f'GPUs available: {len(gpus)}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNVZRezpnwlV",
        "outputId": "2314cd16-b169-44f5-f99a-db928de3a26f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração de uso gradual e necessário da memória da GPU utilizada"
      ],
      "metadata": {
        "id": "tBDBgymJoECi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f'{len(gpus)} physical GPUs vs. {len(logical_gpus)} logical GPUs')\n",
        "        \n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GcgIaH9XoE5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constantes"
      ],
      "metadata": {
        "id": "EnCLKLG9og3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SZ = 200"
      ],
      "outputs": [],
      "metadata": {
        "id": "CNe0BZkHokLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RANDOM_SEED = 42"
      ],
      "outputs": [],
      "metadata": {
        "id": "0FRgMFMDo1UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados"
      ],
      "metadata": {
        "id": "2FiWg76aptvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATCH_STEP = 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "4AJ4EW5HCRpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DT_BUFFER_SZ = 150"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lwnnmbtnn3_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_PROPORTION = .2"
      ],
      "outputs": [],
      "metadata": {
        "id": "6rKj41ofVL5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "XVALIDATION_PROPORTION = .65"
      ],
      "outputs": [],
      "metadata": {
        "id": "0-UDTg4lo7GY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# represent voxels located in the:\n",
        "# 0: background\n",
        "# 1: RV cavity\n",
        "# 2: myocardium\n",
        "# 3: LV cavity \n",
        "CLASSES_CNT = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "teZ1vFnBo86-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TRAINING_FILENAME = 'training.zip'\n",
        "TRAINING_DIR = 'ACDC/train'\n",
        "\n",
        "TRAINING_FILENAME = os.path.join(*drive_path, TRAINING_FILENAME)\n",
        "TRAINING_DIR = os.path.join(*drive_path, TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FypEp4tTqFOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "Z5tTzWDkqmFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_FILENAME = 'ulas_model'"
      ],
      "outputs": [],
      "metadata": {
        "id": "RE7z_CNNqoiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_DIR = os.path.join(*drive_path, MODEL_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QW8kwOYwqsS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas e Funções de perda"
      ],
      "metadata": {
        "id": "M_VUxpZxt5IE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "SMOOTH = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "wpy8ho6IGiTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TVERSKY_FN_WEIGHT = .7"
      ],
      "outputs": [],
      "metadata": {
        "id": "YHWuvgnRt4Vx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "TVERSKY_FOCAL = .5"
      ],
      "outputs": [],
      "metadata": {
        "id": "SMmOYOCnt_Gg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "FOCAL_LOSS_GAMA = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "d0NCWDkVuDMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento"
      ],
      "metadata": {
        "id": "abjYtJ7zp2Bj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INIT_LEARNING_RATE = 1e-4"
      ],
      "outputs": [],
      "metadata": {
        "id": "gPy_ujYcpDiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MIN_LEARNING_RATE = 1e-6"
      ],
      "outputs": [],
      "metadata": {
        "id": "DExT9SdYpNCm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BATCH_SIZE = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "kAAyIdURprUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAIN_METRIC = 'dice_metric'"
      ],
      "outputs": [],
      "metadata": {
        "id": "R7LBrU0Ptpw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if MODEL_FILENAME == 'unet_plusplus_model':\n",
        "    EVAL_METRIC = f're_lu_{MAIN_METRIC}'\n",
        "else:\n",
        "    EVAL_METRIC = MAIN_METRIC"
      ],
      "outputs": [],
      "metadata": {
        "id": "gIERQ-Kqtt3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestones do treinamento"
      ],
      "metadata": {
        "id": "A_lgkcSdrq25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "EARLY_STOP_PATIENCE = 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "fp0RTecqsvC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_FILENAME = os.path.join(\n",
        "    MODEL_DIR,\n",
        "    '{}_improvement_{}.h5'.format(\n",
        "        MODEL_FILENAME,\n",
        "        '{}_{}'.format(\n",
        "            '{epoch:02d}',\n",
        "            ''.join(['{', f'val_{EVAL_METRIC}:.2f', '}'])\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "asIAvRtHs5Rh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CSV_LOG_FILENAME = os.path.join(MODEL_DIR, f'{MODEL_FILENAME}_log.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y8OTM6KNs-vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados"
      ],
      "metadata": {
        "id": "MkYM5QDBtPul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_FILENAME = f'{MODEL_FILENAME}_structure.png'\n",
        "PLOT_FILENAME = os.path.join(MODEL_DIR, PLOT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VAkIzuNPtOzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_WIDTH = 720"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8k9BznKtWcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aquisição das imagens"
      ],
      "metadata": {
        "id": "jRA4xxMDuLRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports desta seção"
      ],
      "metadata": {
        "id": "eLKawJgfvLcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.image import extract_patches\n",
        "from tensorflow.keras.utils import normalize, to_categorical"
      ],
      "outputs": [],
      "metadata": {
        "id": "6DctGw4bvN7t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "author: Clément Zotti (clement.zotti@usherbrooke.ca)\n",
        "date: April 2017\n",
        "\n",
        "DESCRIPTION :\n",
        "The script provide helpers functions to handle nifti image format:\n",
        "    - load_nii()\n",
        "    - save_nii()\n",
        "\n",
        "to generate metrics for two images:\n",
        "    - metrics()\n",
        "\n",
        "And it is callable from the command line (see below).\n",
        "Each function provided in this script has comments to understand\n",
        "how they works.\n",
        "\n",
        "HOW-TO:\n",
        "\n",
        "This script was tested for python 3.4.\n",
        "\n",
        "First, you need to install the required packages with\n",
        "    pip install -r requirements.txt\n",
        "\n",
        "After the installation, you have two ways of running this script:\n",
        "    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n",
        "    2) python metrics.py ground_truth/ prediction/\n",
        "\n",
        "The first option will print in the console the dice and volume of each class for the given image.\n",
        "The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n",
        "\n",
        "\n",
        "Based on: http://acdc.creatis.insa-lyon.fr\n",
        "\"\"\"\n",
        "#\n",
        "# Utils function to load and save nifti files with the nibabel package\n",
        "#\n",
        "def load_nii(img_path):\n",
        "    \"\"\"\n",
        "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
        "    everyting needed to save another 'nii' or 'nii.gz'\n",
        "    in the same dimensional space, i.e. the affine matrix and the header\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Three element, the first is a numpy array of the image values,\n",
        "    the second is the affine transformation of the image, and the\n",
        "    last one is the header of the image.\n",
        "    \"\"\"\n",
        "    nimg = nib.load(img_path)\n",
        "    return nimg.get_fdata().astype('float32'), nimg.affine, nimg.header\n",
        "\n",
        "def save_nii(img_path, data, affine, header):\n",
        "    \"\"\"\n",
        "    Function to save a 'nii' or 'nii.gz' file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
        "\n",
        "    data: np.array\n",
        "    Numpy array of the image data.\n",
        "\n",
        "    affine: list of list or np.array\n",
        "    The affine transformation to save with the image.\n",
        "\n",
        "    header: nib.Nifti1Header\n",
        "    The header that define everything about the data\n",
        "    (pleasecheck nibabel documentation).\n",
        "    \"\"\"\n",
        "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
        "    nimg.to_filename(img_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fosux3OuQkB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def file_paths(base_dir):\n",
        "    c_paths = {\n",
        "        'config': [],\n",
        "        'ground_truth': [],\n",
        "        'images': [],\n",
        "        '4d': []\n",
        "    }\n",
        "\n",
        "    for c_dir, next_dirs, file_names in os.walk(base_dir):\n",
        "        # skip root\n",
        "        if next_dirs:\n",
        "            continue\n",
        "\n",
        "        c_patient = os.path.basename(c_dir)\n",
        "\n",
        "        for f_n in file_names:\n",
        "            f_n = os.path.join(c_dir, f_n)\n",
        "\n",
        "            if f_n.endswith('.cfg'): file_type = 'config'\n",
        "            elif '_gt' in f_n: file_type = 'ground_truth'\n",
        "            elif '_4d' in f_n: file_type = '4d'\n",
        "            else: file_type = 'images'\n",
        "\n",
        "            c_paths[file_type].append(f_n)\n",
        "\n",
        "    for file_type in c_paths.keys():\n",
        "        c_paths[file_type].sort()\n",
        "\n",
        "    return c_paths\n",
        "\n",
        "def load_data(file_paths, is_training=True):\n",
        "    images_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_data.npy')\n",
        "    gt_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_gt_data.npy')\n",
        "\n",
        "    try:\n",
        "        imgs = np.load(images_filename, allow_pickle=True)\n",
        "        imgs_gt = np.load(gt_filename, allow_pickle=True)\n",
        "\n",
        "        if np.any(imgs) and np.any(imgs_gt):\n",
        "            print('carregado dos arquivos')\n",
        "\n",
        "            return tf.convert_to_tensor(imgs), tf.convert_to_tensor(imgs_gt)\n",
        "    except:\n",
        "        print('carregando arquivos')\n",
        "        imgs, imgs_gt =  _load_data(file_paths)\n",
        "\n",
        "        np.save(images_filename, imgs)\n",
        "        np.save(gt_filename, imgs_gt)\n",
        "\n",
        "        return imgs, imgs_gt\n",
        "\n",
        "def _load_data(file_paths):\n",
        "    images, ground_truth = [], []\n",
        "    cnt = 1\n",
        "\n",
        "    for c_img, c_ground_truth in zip(file_paths['images'], file_paths['ground_truth']):\n",
        "        print(f'processing {cnt}...')\n",
        "\n",
        "        # we load 3D training image\n",
        "        training_image, _, _ = load_nii(c_img)\n",
        "        # we load 3D training mask (shape=(512,512,129))\n",
        "        train_ground_truth, _, _ = load_nii(c_ground_truth)\n",
        "\n",
        "        for k in range(min(train_ground_truth.shape[-1], training_image.shape[-1])):\n",
        "            #axial cuts are made along the z axis with undersampling\n",
        "            gt_2d = np.array(train_ground_truth[::, ::, k])\n",
        "\n",
        "            # invalid ground truth\n",
        "            if len(np.unique(gt_2d)) == 1:\n",
        "                continue\n",
        "\n",
        "            image_patches = _extract_patches(\n",
        "                _pre_process_img(np.array(training_image[::, ::, k]))\n",
        "            )\n",
        "            gt_patches = _extract_patches(gt_2d)\n",
        "\n",
        "            if (tf.size(images) == 0).numpy():\n",
        "                images = image_patches\n",
        "            else:\n",
        "                images = tf.concat((images, image_patches), axis=0)\n",
        "\n",
        "            if (tf.size(ground_truth) == 0).numpy():\n",
        "                ground_truth = gt_patches\n",
        "            else:\n",
        "                ground_truth = tf.concat((ground_truth, gt_patches), axis=0)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "    ground_truth = tf.cast(ground_truth, tf.int32)\n",
        "\n",
        "    return images, ground_truth\n",
        "\n",
        "def _extract_patches(image_2d):\n",
        "    image_2d = tf.expand_dims(tf.expand_dims(image_2d, axis=-1), axis=0)\n",
        "\n",
        "    if image_2d.shape[1] < IMG_SZ or image_2d.shape[2] < IMG_SZ:\n",
        "        return tf.image.resize(\n",
        "            image_2d, (IMG_SZ, IMG_SZ), method='nearest'\n",
        "        )\n",
        "\n",
        "    image_patches = extract_patches(\n",
        "        image_2d,\n",
        "        sizes=[1, IMG_SZ, IMG_SZ, 1],\n",
        "        strides=[1, PATCH_STEP, PATCH_STEP, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    return tf.reshape(\n",
        "        image_patches,\n",
        "        [image_patches.shape[1] * image_patches.shape[2], IMG_SZ, IMG_SZ, 1]\n",
        "    )\n",
        "\n",
        "# Based on: https://github.com/MinaJf/FU-net/blob/HEAD/image_loder.py\n",
        "def _pre_process_img(img):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # standardization (zero mean)\n",
        "    img -= tf.math.reduce_mean(img)\n",
        "    img /= tf.math.reduce_std(img)\n",
        "\n",
        "    # normalize between [0, 1]\n",
        "    img -= tf.math.reduce_min(img)\n",
        "    img /= tf.math.reduce_max(img)\n",
        "\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "7rDOEKiCvsVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando dados"
      ],
      "metadata": {
        "id": "bBnxc1TaUIsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "wJBLyaJoUSef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import unique\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZCDybhaqURto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def to_dataset(data, labels):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
        "    dataset = dataset.shuffle(\n",
        "        buffer_size=DT_BUFFER_SZ,\n",
        "        seed=RANDOM_SEED,\n",
        "        reshuffle_each_iteration=True\n",
        "    )\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(2)\n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "YAtsCK5AnFJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "training_paths = file_paths(TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "xgYXN9Mz5Lpl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(len(training_paths['config']))\n",
        "print(len(training_paths['ground_truth']))\n",
        "print(len(training_paths['images']))\n",
        "print(len(training_paths['4d']))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywop8DyCka3Y",
        "outputId": "165ff39a-50c0-4e19-fc21-b576ac50becc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "raw_train_data, raw_train_labels = load_data(training_paths)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRbfZ2Mw6Jmh",
        "outputId": "246d6885-8c25-4ffd-e2e8-ae79d3baf802"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f'raw_train_data: {raw_train_data.shape}\\n\\t{raw_train_data.dtype}')\n",
        "print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ4UDaVRGYrw",
        "outputId": "2cbdd432-29f3-479c-c90f-b2305dc59488"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "classes_weight = compute_class_weight(\n",
        "    'balanced',\n",
        "    unique(raw_train_labels),\n",
        "    tf.reshape(raw_train_labels, tf.size(raw_train_labels)).numpy()\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEQASGF_bFW8",
        "outputId": "bc6a9e1c-8f12-4c66-f2d2-345a3b9edce7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f'classes_weight: {len(classes_weight)}\\n{classes_weight}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTr9988Rb7Du",
        "outputId": "0d505864-3a6b-43d8-e2a4-89e0680527d6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "raw_train_labels = to_categorical(raw_train_labels, CLASSES_CNT, dtype='int32')\n",
        "print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC3AagLlbY9u",
        "outputId": "2aabf1cd-b2c4-4641-f249-440fb73d8ca4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    raw_train_data.numpy(), raw_train_labels,\n",
        "    test_size=VALIDATION_PROPORTION,\n",
        "    random_state=RANDOM_SEED\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "h82EnnK7Uxls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f'test_data: {test_data.shape}')\n",
        "print(f'test_labels: {test_labels.shape}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOV5wKxOV71r",
        "outputId": "76064b5a-f618-4f40-ca21-b520d9f7cd85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_data, xval_data, train_labels, xval_labels = train_test_split(\n",
        "    train_data, train_labels,\n",
        "    test_size=XVALIDATION_PROPORTION,\n",
        "    random_state=RANDOM_SEED\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "TILS5we-WH6M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(f'train_data: {train_data.shape}')\n",
        "print(f'xval_data: {xval_data.shape}')\n",
        "print(f'train_labels: {train_labels.shape}')\n",
        "print(f'xval_labels: {xval_labels.shape}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjoRxciPWSAi",
        "outputId": "d134f36b-5b0d-4b53-f910-78c4434972e6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_dataset = to_dataset(train_data, train_labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4TDvEa1goyJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_dataset = to_dataset(xval_data, xval_labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WrdS_4yAo4B8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_dataset = to_dataset(test_data, test_labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Gkfqjoc3o4b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-visualização"
      ],
      "metadata": {
        "id": "6dOZ5954W5Df"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rnd_idx = randint(0, len(train_data) - 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2)\n",
        "\n",
        "train_img = tf.squeeze(train_data[rnd_idx], axis=2)\n",
        "train_gt = tf.argmax(train_labels[rnd_idx], axis=2)\n",
        "\n",
        "axes[0].imshow(train_img, cmap='hot')\n",
        "axes[1].imshow(train_gt, cmap='hot')\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4rx_lhqAYyoN",
        "outputId": "f335a45c-f8fc-4831-c274-5a005eec5594"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas manuais"
      ],
      "metadata": {
        "id": "UlEma1WCF49k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "cHLZZaBVF9vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "HpUXCOL2GABF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def inter_union_sum(y_true, y_pred):\n",
        "    # W,H axes of each image\n",
        "    axes = (1,2)\n",
        "    \n",
        "    intersection = K.sum(K.abs(y_pred * y_true), axis=axes)\n",
        "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection\n",
        "\n",
        "    return intersection, union, mask_sum"
      ],
      "outputs": [],
      "metadata": {
        "id": "RMc9OGrhGeoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def dice_metric(y_true, y_pred):\n",
        "    # 2*|A & B| / (|A| + |B|)\n",
        "    intersection, _, mask_sum = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    dice = 2 * (intersection + SMOOTH)/(mask_sum + SMOOTH)\n",
        "\n",
        "    return K.mean(dice)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F82GF0c8HNye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def jaccard_metric(y_true, y_pred):\n",
        "    # |A & B| / (| A U B|)\n",
        "    intersection, union, _ = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    jaccard = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "\n",
        "    return K.mean(jaccard)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GPs64AkvH3S4"
      }
    }
  ]
}