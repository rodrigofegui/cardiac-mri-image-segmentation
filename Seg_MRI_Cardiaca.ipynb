{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Seg_MRI_Cardiaca.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HC4K3T4SmEf_",
        "eKFfei90mcAJ",
        "EnCLKLG9og3I",
        "jRA4xxMDuLRG",
        "hcEtyDUbOIcw",
        "UlEma1WCF49k",
        "w7JKL6lA3CmT",
        "MP_30iwQG5Pf",
        "iIDrnFqqI8yY",
        "hRDKvbFVwLL0",
        "NHNgrwTVUFzc",
        "s1agFI3Xyrws",
        "mZjKdfiev5pT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Segmentação de MRI Cardíacas**\n",
        "\n"
      ],
      "metadata": {
        "id": "HC4K3T4SmEf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "eKFfei90mcAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas"
      ],
      "metadata": {
        "id": "z14WjMKNmnIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "\n",
        "!pip install scikit-learn==0.24.2\n",
        "!pip install segmentation-models==1.0.1\n",
        "\n",
        "!pip install nibabel==3.2.1\n",
        "!pip install MedPy==0.4.0\n",
        "\n",
        "!pip install matplotlib==3.2.2"
      ],
      "outputs": [],
      "metadata": {
        "id": "NfB9dnKSl-VP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22dac137-2fe1-40de-f813-35c0cc99dd8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acesso à arquivos do Gdrive"
      ],
      "metadata": {
        "id": "UzHCSwCdnIHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "drive_path = [\n",
        "    '/content/drive',\n",
        "    'My Drive/Colab Notebooks/data'\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "XNB6SCUQxhTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(drive_path[0], force_remount=True)\n",
        "os.chdir('/'.join(drive_path))\n",
        "sys.path.append('/'.join(drive_path))"
      ],
      "outputs": [],
      "metadata": {
        "id": "JQl43uvenSLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca331b5b-debf-45cb-8e9e-9197fba68d61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualização da GPU disponibilizada"
      ],
      "metadata": {
        "id": "9VAnelmOnebU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [],
      "metadata": {
        "id": "0TmRxKiCnnCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce349613-a50b-436b-d04b-986efe28ee43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizando a quantidade de GPUs detectadas"
      ],
      "metadata": {
        "id": "9HRMYmjznryn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(f'GPUs available: {len(gpus)}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "kNVZRezpnwlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06875fa-461c-47a7-9d5d-35fc9d5351af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração de uso gradual e necessário da memória da GPU utilizada"
      ],
      "metadata": {
        "id": "tBDBgymJoECi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(f'{len(gpus)} physical GPUs vs. {len(logical_gpus)} logical GPUs')\n",
        "        \n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GcgIaH9XoE5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constantes"
      ],
      "metadata": {
        "id": "EnCLKLG9og3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.data import AUTOTUNE\n",
        "from os.path import join as join_path"
      ],
      "outputs": [],
      "metadata": {
        "id": "MdsW27iD28sA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SZ = 200"
      ],
      "outputs": [],
      "metadata": {
        "id": "CNe0BZkHokLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "RANDOM_SEED = 42"
      ],
      "outputs": [],
      "metadata": {
        "id": "0FRgMFMDo1UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens"
      ],
      "metadata": {
        "id": "2FiWg76aptvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# represent voxels located in the:\n",
        "# 0: background\n",
        "# 1: RV cavity\n",
        "# 2: myocardium\n",
        "# 3: LV cavity \n",
        "CLASSES_CNT = 4"
      ],
      "outputs": [],
      "metadata": {
        "id": "teZ1vFnBo86-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INPUT_CHANNELS = 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "yhPLtcgFIBS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATCH_STEP = 18"
      ],
      "outputs": [],
      "metadata": {
        "id": "4AJ4EW5HCRpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_SUFIX = '_data'"
      ],
      "outputs": [],
      "metadata": {
        "id": "0jmhXzzrjHUd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_SUFIX = '_mask'"
      ],
      "outputs": [],
      "metadata": {
        "id": "388ZVEbVjKoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CLASS_WEIGHT_FILENAME = 'classes_weight.npy'\n",
        "CLASS_WEIGHT_FILENAME = join_path(*drive_path, CLASS_WEIGHT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PFpk9RQXpLGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data-subgroup"
      ],
      "metadata": {
        "id": "OWKzttYtjp7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "6rKj41ofVL5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "XVALIDATION_PROPORTION = .25"
      ],
      "outputs": [],
      "metadata": {
        "id": "0-UDTg4lo7GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets"
      ],
      "metadata": {
        "id": "fo7dJMWKjNRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DT_BUFFER_SZ = 16"
      ],
      "outputs": [],
      "metadata": {
        "id": "Lwnnmbtnn3_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PREFETCH_DATA_SZ = AUTOTUNE"
      ],
      "outputs": [],
      "metadata": {
        "id": "XytTiCOEMrPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BASE_DATA_DIR = 'ACDC_2017_dados'\n",
        "\n",
        "RAW_TRAINING_FILENAME = 'training.zip'\n",
        "RAW_TRAINING_DIR = 'raw_train'\n",
        "PATCHES_DIR = 'image_patches'\n",
        "TRAINING_DIR = 'train'\n",
        "X_VAL_DIR = 'validation'\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "RAW_TRAINING_DIR = join_path(BASE_DATA_DIR, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, X_VAL_DIR)\n",
        "TEST_DIR = join_path(BASE_DATA_DIR, PATCHES_DIR, TEST_DIR)\n",
        "\n",
        "RAW_TRAINING_FILENAME = join_path(*drive_path, RAW_TRAINING_FILENAME)\n",
        "RAW_TRAINING_DIR = join_path(*drive_path, RAW_TRAINING_DIR)\n",
        "TRAINING_DIR = join_path(*drive_path, TRAINING_DIR)\n",
        "X_VAL_DIR = join_path(*drive_path, X_VAL_DIR)\n",
        "TEST_DIR = join_path(*drive_path, TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FypEp4tTqFOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "IMG_GLOB_SEARCH = ''.join(['*', IMG_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "VlmtbvhYk-Zh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MASK_GLOB_SEARCH = ''.join(['*', MASK_SUFIX, '.npy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPBLY1dCTjwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos"
      ],
      "metadata": {
        "id": "Z5tTzWDkqmFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_FILENAME = 'ulas_model'\n",
        "MODEL_FILENAME = 'ulas_model_v2'\n",
        "# MODEL_FILENAME = 'linknet_model'\n",
        "# MODEL_FILENAME = 'unet_model'"
      ],
      "outputs": [],
      "metadata": {
        "id": "RE7z_CNNqoiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MODEL_DIR = join_path(*drive_path, MODEL_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QW8kwOYwqsS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquitetura Ulas"
      ],
      "metadata": {
        "id": "2lEQdpd8K_la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "POOL_SIZE = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "nPkeN2YyLCtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas e Funções de perda"
      ],
      "metadata": {
        "id": "M_VUxpZxt5IE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "SMOOTH = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "wpy8ho6IGiTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "FOCAL_LOSS_GAMA = 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "d0NCWDkVuDMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento"
      ],
      "metadata": {
        "id": "abjYtJ7zp2Bj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INIT_LEARNING_RATE = 1e-3"
      ],
      "outputs": [],
      "metadata": {
        "id": "gPy_ujYcpDiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MIN_LEARNING_RATE = 1e-6"
      ],
      "outputs": [],
      "metadata": {
        "id": "DExT9SdYpNCm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "BATCH_SIZE = 32"
      ],
      "outputs": [],
      "metadata": {
        "id": "kAAyIdURprUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "INITAL_EPOCH = 7"
      ],
      "outputs": [],
      "metadata": {
        "id": "2MGb3tctlHvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAX_EPOCH = 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "cm_NFCiKSIrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MAIN_METRIC = 'dice_metric'"
      ],
      "outputs": [],
      "metadata": {
        "id": "R7LBrU0Ptpw9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if MODEL_FILENAME == 'unet_plusplus_model':\n",
        "    EVAL_METRIC = f're_lu_{MAIN_METRIC}'\n",
        "else:\n",
        "    EVAL_METRIC = MAIN_METRIC"
      ],
      "outputs": [],
      "metadata": {
        "id": "gIERQ-Kqtt3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "METRIC_THRESHOLD = .5"
      ],
      "outputs": [],
      "metadata": {
        "id": "y1p09qit9-Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "IDXFT87zPDUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_ROTATION = 90"
      ],
      "outputs": [],
      "metadata": {
        "id": "WPQ6ps85PF76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_HOR_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "yPicNXYUPKVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_W_VER_FLIP = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "g3hQd0c_PP7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_WIDTH_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "gwViSbPsPdpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_HEIGHT_RNG = .4"
      ],
      "outputs": [],
      "metadata": {
        "id": "UtBEysfLPfoY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_ZOOM = [1, 1.6]"
      ],
      "outputs": [],
      "metadata": {
        "id": "qWvTb7owPgaN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "AUG_FILL_MODE = 'wrap'"
      ],
      "outputs": [],
      "metadata": {
        "id": "40y_uDu-PhU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Milestones do treinamento"
      ],
      "metadata": {
        "id": "A_lgkcSdrq25"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "EARLY_STOP_PATIENCE = 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "fp0RTecqsvC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "LR_REDUCER_PATIENCE = 3"
      ],
      "outputs": [],
      "metadata": {
        "id": "__8-O_YPMhMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_FILENAME = join_path(\n",
        "    MODEL_DIR,\n",
        "    f'{MODEL_FILENAME}.h5'\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "asIAvRtHs5Rh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "CSV_LOG_FILENAME = join_path(MODEL_DIR, f'{MODEL_FILENAME}_log.csv')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y8OTM6KNs-vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados"
      ],
      "metadata": {
        "id": "MkYM5QDBtPul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_FILENAME = f'{MODEL_FILENAME}_structure.png'\n",
        "PLOT_FILENAME = join_path(MODEL_DIR, PLOT_FILENAME)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VAkIzuNPtOzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PLOT_WIDTH = 720"
      ],
      "outputs": [],
      "metadata": {
        "id": "J8k9BznKtWcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação das imagens"
      ],
      "metadata": {
        "id": "jRA4xxMDuLRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports desta seção"
      ],
      "metadata": {
        "id": "eLKawJgfvLcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from time import sleep\n",
        "from numpy import unique\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.image import extract_patches\n",
        "from tensorflow.keras.utils import normalize, to_categorical"
      ],
      "outputs": [],
      "metadata": {
        "id": "6DctGw4bvN7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagens originais, .nii.gz"
      ],
      "metadata": {
        "id": "enXqnOMtiIpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"\n",
        "author: Clément Zotti (clement.zotti@usherbrooke.ca)\n",
        "date: April 2017\n",
        "\n",
        "DESCRIPTION :\n",
        "The script provide helpers functions to handle nifti image format:\n",
        "    - load_nii()\n",
        "    - save_nii()\n",
        "\n",
        "to generate metrics for two images:\n",
        "    - metrics()\n",
        "\n",
        "And it is callable from the command line (see below).\n",
        "Each function provided in this script has comments to understand\n",
        "how they works.\n",
        "\n",
        "HOW-TO:\n",
        "\n",
        "This script was tested for python 3.4.\n",
        "\n",
        "First, you need to install the required packages with\n",
        "    pip install -r requirements.txt\n",
        "\n",
        "After the installation, you have two ways of running this script:\n",
        "    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n",
        "    2) python metrics.py ground_truth/ prediction/\n",
        "\n",
        "The first option will print in the console the dice and volume of each class for the given image.\n",
        "The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n",
        "\n",
        "\n",
        "Based on: http://acdc.creatis.insa-lyon.fr\n",
        "\"\"\"\n",
        "#\n",
        "# Utils function to load and save nifti files with the nibabel package\n",
        "#\n",
        "def load_nii(img_path):\n",
        "    \"\"\"\n",
        "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
        "    everyting needed to save another 'nii' or 'nii.gz'\n",
        "    in the same dimensional space, i.e. the affine matrix and the header\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Three element, the first is a numpy array of the image values,\n",
        "    the second is the affine transformation of the image, and the\n",
        "    last one is the header of the image.\n",
        "    \"\"\"\n",
        "    nimg = nib.load(img_path)\n",
        "    return nimg.get_fdata().astype('float32'), nimg.affine, nimg.header\n",
        "\n",
        "def save_nii(img_path, data, affine, header):\n",
        "    \"\"\"\n",
        "    Function to save a 'nii' or 'nii.gz' file.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    img_path: string\n",
        "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
        "\n",
        "    data: np.array\n",
        "    Numpy array of the image data.\n",
        "\n",
        "    affine: list of list or np.array\n",
        "    The affine transformation to save with the image.\n",
        "\n",
        "    header: nib.Nifti1Header\n",
        "    The header that define everything about the data\n",
        "    (pleasecheck nibabel documentation).\n",
        "    \"\"\"\n",
        "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
        "    nimg.to_filename(img_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "8fosux3OuQkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Localização dos arquivos"
      ],
      "metadata": {
        "id": "ppq0c2DAimvE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def file_paths(base_dir):\n",
        "    c_paths = {\n",
        "        'config': [],\n",
        "        'ground_truth': [],\n",
        "        'images': [],\n",
        "        '4d': []\n",
        "    }\n",
        "\n",
        "    for c_dir, next_dirs, file_names in os.walk(base_dir):\n",
        "        # skip root\n",
        "        if next_dirs:\n",
        "            continue\n",
        "\n",
        "        c_patient = os.path.basename(c_dir)\n",
        "\n",
        "        for f_n in file_names:\n",
        "            f_n = os.path.join(c_dir, f_n)\n",
        "\n",
        "            if f_n.endswith('.cfg'): file_type = 'config'\n",
        "            elif '_gt' in f_n: file_type = 'ground_truth'\n",
        "            elif '_4d' in f_n: file_type = '4d'\n",
        "            else: file_type = 'images'\n",
        "\n",
        "            c_paths[file_type].append(f_n)\n",
        "\n",
        "    for file_type in c_paths.keys():\n",
        "        c_paths[file_type].sort()\n",
        "\n",
        "    return c_paths"
      ],
      "outputs": [],
      "metadata": {
        "id": "XLJTixvmiP5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversões diretas salvas"
      ],
      "metadata": {
        "id": "3XN_in9viXpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def load_data(file_paths, is_training=True):\n",
        "    images_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_data.npy')\n",
        "    gt_filename = os.path.join(*drive_path, f'{\"training\" if is_training else \"test\"}_gt_data.npy')\n",
        "\n",
        "    try:\n",
        "        imgs = np.load(images_filename, allow_pickle=True)\n",
        "        imgs_gt = np.load(gt_filename, allow_pickle=True)\n",
        "\n",
        "        if np.any(imgs) and np.any(imgs_gt):\n",
        "            print('carregado dos arquivos')\n",
        "\n",
        "            return tf.convert_to_tensor(imgs), tf.convert_to_tensor(imgs_gt, dtype=tf.float32)\n",
        "    except:\n",
        "        print('lendo imagens arquivos')\n",
        "        imgs, imgs_gt =  _load_data(file_paths)\n",
        "\n",
        "        # np.save(images_filename, imgs)\n",
        "        # np.save(gt_filename, imgs_gt)\n",
        "\n",
        "        return imgs, imgs_gt\n",
        "\n",
        "def load_classes_weight(labels=None):\n",
        "    return None\n",
        "    try:\n",
        "        weights = np.load(CLASS_WEIGHT_FILENAME, allow_pickle=True)\n",
        "\n",
        "        if np.any(weights):\n",
        "            print('carregado do arquivo')\n",
        "\n",
        "            return weights\n",
        "    except:\n",
        "        print('calculando pesos')\n",
        "        if not np.any(labels):\n",
        "            return None\n",
        "\n",
        "        weights = compute_class_weight(\n",
        "            'balanced',\n",
        "            np.arange(CLASSES_CNT),\n",
        "            tf.reshape(tf.cast(labels, tf.int8), [-1]).numpy()\n",
        "        )\n",
        "\n",
        "        np.save(CLASS_WEIGHT_FILENAME, weights)\n",
        "\n",
        "        return weights"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZfLGFpW2iV19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento das imagens originais"
      ],
      "metadata": {
        "id": "gEiOw6_JitX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_data(file_paths):\n",
        "    images, ground_truth = [], []\n",
        "    cnt = 1\n",
        "\n",
        "    for c_img, c_ground_truth in zip(file_paths['images'], file_paths['ground_truth']):\n",
        "        print(f'processing {cnt}...')\n",
        "\n",
        "        # we load 3D training image\n",
        "        training_image, _, _ = load_nii(c_img)\n",
        "        # we load 3D training mask (shape=(512,512,129))\n",
        "        train_ground_truth, _, _ = load_nii(c_ground_truth)\n",
        "\n",
        "        for k in range(min(train_ground_truth.shape[-1], training_image.shape[-1])):\n",
        "            #axial cuts are made along the z axis with undersampling\n",
        "            gt_2d = np.array(train_ground_truth[::, ::, k])\n",
        "\n",
        "            # invalid ground truth\n",
        "            if len(np.unique(gt_2d)) == 1:\n",
        "                continue\n",
        "\n",
        "            image_patches = _extract_patches(\n",
        "                _pre_process_img(np.array(training_image[::, ::, k]))\n",
        "            )\n",
        "            gt_patches = _extract_patches(gt_2d)\n",
        "\n",
        "            if (tf.size(images) == 0).numpy():\n",
        "                images = image_patches\n",
        "            else:\n",
        "                images = tf.concat((images, image_patches), axis=0)\n",
        "\n",
        "            if (tf.size(ground_truth) == 0).numpy():\n",
        "                ground_truth = gt_patches\n",
        "            else:\n",
        "                ground_truth = tf.concat((ground_truth, gt_patches), axis=0)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "    return images, ground_truth\n",
        "\n",
        "def _extract_patches(image_2d):\n",
        "    image_2d = tf.expand_dims(tf.expand_dims(image_2d, axis=-1), axis=0)\n",
        "\n",
        "    if image_2d.shape[1] < IMG_SZ or image_2d.shape[2] < IMG_SZ:\n",
        "        return tf.image.resize(\n",
        "            image_2d, (IMG_SZ, IMG_SZ), method='nearest'\n",
        "        )\n",
        "\n",
        "    image_patches = extract_patches(\n",
        "        image_2d,\n",
        "        sizes=[1, IMG_SZ, IMG_SZ, 1],\n",
        "        strides=[1, PATCH_STEP, PATCH_STEP, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding='VALID'\n",
        "    )\n",
        "\n",
        "    return tf.reshape(\n",
        "        image_patches,\n",
        "        [image_patches.shape[1] * image_patches.shape[2], IMG_SZ, IMG_SZ, 1]\n",
        "    )\n",
        "\n",
        "# Based on: https://github.com/MinaJf/FU-net/blob/HEAD/image_loder.py\n",
        "def _pre_process_img(img):\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # standardization (zero mean)\n",
        "    img -= tf.math.reduce_mean(img)\n",
        "    img /= tf.math.reduce_std(img)\n",
        "\n",
        "    # normalize between [0, 1]\n",
        "    img -= tf.math.reduce_min(img)\n",
        "    img /= tf.math.reduce_max(img)\n",
        "\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "7rDOEKiCvsVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_patches(patches, base_dir, is_label=False):\n",
        "    for ind, img in enumerate(patches, start=1):\n",
        "        img_name = f'{ind}{MASK_SUFIX if is_label else IMG_SUFIX}'\n",
        "        img_path = os.path.join(base_dir, img_name)\n",
        "\n",
        "        np.save(img_path, img)\n",
        "        # while True:\n",
        "        #     print(f'\\t a salvar...')\n",
        "        #     sleep(2)\n",
        "\n",
        "        #     if os.path.exists(img_path): break\n",
        "            \n",
        "        print(f'saved {img_path}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y4fDYPWhh_4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulação dos dados"
      ],
      "metadata": {
        "id": "Al2EYzA3kFup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.data import Dataset\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from numpy import load\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing.image as img_preprocessing"
      ],
      "outputs": [],
      "metadata": {
        "id": "vyBVdSOHkKfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def check_cnt(main_path):\n",
        "    img_cnt = len(glob(os.path.join(main_path, IMG_GLOB_SEARCH)))\n",
        "    mask_cnt = len(glob(os.path.join(main_path, MASK_GLOB_SEARCH)))\n",
        "\n",
        "    print('img_cnt', img_cnt)\n",
        "    print('mask_cnt', mask_cnt)\n",
        "\n",
        "    return img_cnt if img_cnt == mask_cnt else 0"
      ],
      "outputs": [],
      "metadata": {
        "id": "0JpDzETkm9wQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _load_images(path_batch):\n",
        "    images, masks = [], []\n",
        "\n",
        "    print('*' * 20)\n",
        "    for img_path in path_batch:\n",
        "        img_path = img_path.decode()\n",
        "\n",
        "        image = load(img_path, allow_pickle=True)\n",
        "\n",
        "        mask_path = img_path.replace(IMG_SUFIX, MASK_SUFIX)\n",
        "\n",
        "        print(img_path)\n",
        "        print(mask_path)\n",
        "        print()\n",
        "        \n",
        "        mask = load(mask_path, allow_pickle=True)\n",
        "      \n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "\n",
        "    return images, masks"
      ],
      "outputs": [],
      "metadata": {
        "id": "6uHK3-WqkNMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def ensure_shape(img_batch, mask_batch):\n",
        "    img_batch = tf.convert_to_tensor(img_batch)\n",
        "    mask_batch = tf.convert_to_tensor(mask_batch)\n",
        "\n",
        "    img_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "    mask_batch.set_shape((None, IMG_SZ, IMG_SZ, 1))\n",
        "\n",
        "    return img_batch, mask"
      ],
      "outputs": [],
      "metadata": {
        "id": "sLLRl-FPkZal"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def pre_processing(img_batch, mask_batch):\n",
        "    mask_batch = tf.cast(mask_batch, tf.int32)\n",
        "    mask_batch = tf.squeeze(mask_batch)\n",
        "\n",
        "    if len(mask_batch.shape) == 3 and mask_batch.shape[-1] == 1:\n",
        "        mask_batch = tf.one_hot(mask_batch, CLASSES_CNT)\n",
        "        \n",
        "    return img_batch, mask_batch"
      ],
      "outputs": [],
      "metadata": {
        "id": "XZIfFEoArrIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "@tf.function\n",
        "def data_augmentation(img_batch, mask_batch):\n",
        "\n",
        "    return img_batch, mask_batch\n",
        "    from random import choice\n",
        "    \n",
        "    yes_no = [True, False]\n",
        "    new_img_batch, new_mask_batch = [], []\n",
        "    # choices = [for _ img_batch.shape[0]]\n",
        "    # for _ in iter(img_batch):\n",
        "    for ind in range(img_batch.shape[0] or mask_batch.shape[0]):\n",
        "        c_img = img_batch[ind]\n",
        "        c_mask = mask_batch[ind]\n",
        "\n",
        "        # horizontal_flip=True,\n",
        "        if choice(yes_no):\n",
        "            c_img = tf.image.flip_left_right(c_img)\n",
        "            c_mask = tf.image.flip_left_right(c_mask)\n",
        "\n",
        "        # vertical_flip=True,\n",
        "        if choice(yes_no):\n",
        "            c_img = tf.image.flip_up_down(c_img)\n",
        "            c_mask = tf.image.flip_up_down(c_mask)\n",
        "\n",
        "        new_img_batch.append(c_img)\n",
        "        new_mask_batch.append(c_mask)\n",
        "\n",
        "\n",
        "\t# fill_mode=\"wrap\"\n",
        "\n",
        "    # print('*' * 20)\n",
        "    # print('image', type(img_batch), img_batch.shape)\n",
        "    # print('mask_batch', type(mask_batch), mask_batch.shape)\n",
        "    # img_batch = tf.image.random_flip_left_right(img_batch, seed=RANDOM_SEED)\n",
        "    # mask_batch = tf.image.random_flip_left_right(mask_batch, seed=RANDOM_SEED)\n",
        "    # # print(type(image), image.shape)\n",
        "    # # vertical_flip=True,\n",
        "    # img_batch = tf.image.random_flip_up_down(img_batch, seed=RANDOM_SEED)\n",
        "    # mask_batch = tf.image.random_flip_up_down(mask_batch, seed=RANDOM_SEED)\n",
        "\n",
        "    # # # width_shift_range=.4,\n",
        "    # # height_shift_range=.4,\n",
        "    \n",
        "    # print(type(image), image.shape)\n",
        "    # image = img_preprocessing.random_shift(\n",
        "    #     img_preprocessing.array_to_img(image[0]), .4, .4, fill_mode='wrap'\n",
        "    # )\n",
        "    # print(type(image), image.shape)\n",
        "\n",
        "    # # rotation_range=90,\n",
        "    # image = img_preprocessing.random_rotation(image, 90, fill_mode='wrap')\n",
        "\n",
        "    # # zoom_range=[1, 1.6],\n",
        "    # image = img_preprocessing.random_zoom(image, (1, 1.6))\n",
        "\n",
        "    # tf.compat.v1.disable_eager_execution()\n",
        "    # print('*' * 20)\n",
        "\n",
        "    return tf.convert_to_tensor(new_img_batch), tf.convert_to_tensor(new_mask_batch)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7SIIEIy301ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_dataset(main_path, is_allowed_to_shuffle=False):\n",
        "    dataset = Dataset.list_files(os.path.join(main_path, IMG_GLOB_SEARCH), shuffle=True, seed=RANDOM_SEED)\n",
        "    \n",
        "    if is_allowed_to_shuffle:\n",
        "        dataset = dataset.shuffle(\n",
        "            buffer_size=DT_BUFFER_SZ,\n",
        "            seed=RANDOM_SEED,\n",
        "            reshuffle_each_iteration=True\n",
        "        )\n",
        "\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "    dataset = dataset.map(lambda x: tf.numpy_function(_load_images, [x], (tf.float32, tf.float32)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(ensure_shape, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.map(pre_processing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "    # dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.prefetch(1)\n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "DI6iSPxOkcdu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def display_sample(display_list, to_save=False):\n",
        "    \"\"\"Show side-by-side an input image,\n",
        "    the ground truth and the prediction.\n",
        "    \"\"\"\n",
        "    plt.figure(dpi=180)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    if len(display_list) == 3:\n",
        "        equal = display_list[1] * display_list[2]\n",
        "        \n",
        "        display_list.append(equal)\n",
        "        display_list.append(display_list[1] - equal)\n",
        "        display_list.append(display_list[2] - equal)\n",
        "\n",
        "    settings = [\n",
        "        { # 0\n",
        "            'title': 'Input Image',\n",
        "            'pre_processing': lambda x: tf.squeeze(x, axis=2),\n",
        "        },\n",
        "        { # 1\n",
        "            'title': 'Ground Truth',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 2\n",
        "            'title': 'Prediction',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 3\n",
        "            'title': 'Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 4\n",
        "            'title': 'G.T. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "        { # 5\n",
        "            'title': 'Pred. - Match',\n",
        "            'pre_processing': lambda x: tf.argmax(x, axis=2),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    for ind, image in enumerate(display_list):\n",
        "        plt.subplot(1, len(display_list), ind + 1)\n",
        "        plt.title(settings[ind]['title'])\n",
        "        plt.imshow(settings[ind]['pre_processing'](image), cmap='hot')\n",
        "        plt.axis('off')\n",
        "\n",
        "    if to_save and len(display_list) == len(settings):\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.svg'), dpi=300)\n",
        "        plt.savefig(os.path.join(MODEL_DIR, f'comparativo.png'), dpi=300)\n",
        "\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nOYPJSVWwGnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo em mémoria"
      ],
      "metadata": {
        "id": "hcEtyDUbOIcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "m_mBzEfeOOaj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZFteRO3KOQfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Based on: https://github.com/mjbhobe/dl-tensorflow-keras/blob/master/kr_helper_funcs.py\n",
        "def save_model(model, file_name, save_dir):\n",
        "    \"\"\" save the model structure to JSON & weights to HD5 \"\"\"\n",
        "    # check if save_dir exists, else create it\n",
        "    if not os.path.exists(save_dir):\n",
        "        try:\n",
        "            mkdir(save_dir)\n",
        "        except OSError as err:\n",
        "            print(f'Não foi possível criar o repositório \"{save_dir}\", para salvar o modelo. Terminando a execução!')\n",
        "            raise err\n",
        "\n",
        "    # model structure is saved to $(save_dir)/base_file_name.json\n",
        "    # weights are saved to $(save_dir)/base_file_name.h5\n",
        "    model_json = model.to_json()\n",
        "    json_file_path = os.path.join(save_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(save_dir, (file_name + '.h5'))\n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\\n\",\n",
        "    model.save(\n",
        "        h5_file_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "        save_traces=True,\n",
        "    )\n",
        "\n",
        "    print(f'Modelo salvo nos arquivos: \"{json_file_path}\" e \"{h5_file_path}\" ')\n",
        "\n",
        "def load_model(file_name, load_dir):\n",
        "    \"\"\" loads model structure & weights from previously saved state \"\"\"\n",
        "    # model structure is loaded $(load_dir)/base_file_name.json\n",
        "    # weights are loaded from $(load_dir)/base_file_name.h5\n",
        "\n",
        "    # load model from save_path\n",
        "    loaded_model = None\n",
        "    json_file_path = os.path.join(load_dir, (file_name + \".json\"))\n",
        "    h5_file_path = os.path.join(load_dir, (file_name + \".h5\"))\n",
        "\n",
        "    if os.path.exists(json_file_path) and os.path.exists(h5_file_path):\n",
        "        with open(json_file_path, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            loaded_model = model_from_json(loaded_model_json)\n",
        "            loaded_model.load_weights(h5_file_path)\n",
        "\n",
        "        print(f'Modelo construído a partir dos arquivos: \"{json_file_path}\" e \"{h5_file_path}\"')\n",
        "\n",
        "    else:\n",
        "        print(\n",
        "            f'Arquivos não encontrados: \"{(file_name + \".json\")}\" e \"{(file_name + \".h5\")}\", na pasta \"{load_dir}\"'\n",
        "        )\n",
        "\n",
        "    return loaded_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "_9b0an3PObPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas manuais"
      ],
      "metadata": {
        "id": "UlEma1WCF49k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "cHLZZaBVF9vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import backend as K"
      ],
      "outputs": [],
      "metadata": {
        "id": "HpUXCOL2GABF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def inter_union_sum(y_true, y_pred):\n",
        "    # W,H axes of each image\n",
        "    axes = (1,2)\n",
        "    \n",
        "    intersection = K.sum(K.abs(y_pred * y_true), axis=axes)\n",
        "    mask_sum = K.sum(K.abs(y_true), axis=axes) + K.sum(K.abs(y_pred), axis=axes)\n",
        "    union = mask_sum  - intersection\n",
        "\n",
        "    return intersection, union, mask_sum"
      ],
      "outputs": [],
      "metadata": {
        "id": "RMc9OGrhGeoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def dice_metric(y_true, y_pred):\n",
        "    # 2*|A & B| / (|A| + |B|)\n",
        "    intersection, _, mask_sum = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    dice = 2 * (intersection + SMOOTH)/(mask_sum + SMOOTH)\n",
        "\n",
        "    return K.mean(dice)"
      ],
      "outputs": [],
      "metadata": {
        "id": "F82GF0c8HNye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def jaccard_metric(y_true, y_pred):\n",
        "    # |A & B| / (| A U B|)\n",
        "    intersection, union, _ = inter_union_sum(y_true, y_pred)\n",
        "\n",
        "    jaccard = (intersection + SMOOTH) / (union + SMOOTH)\n",
        "\n",
        "    return K.mean(jaccard)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GPs64AkvH3S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquiteturas conhecidas"
      ],
      "metadata": {
        "id": "w7JKL6lA3CmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "5PSNvgqf3F2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from segmentation_models import Linknet, Unet, set_framework"
      ],
      "outputs": [],
      "metadata": {
        "id": "kvk8GdP63HfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4893169-cb06-4e90-ca2c-e2105be37170"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "set_framework('tf.keras')"
      ],
      "outputs": [],
      "metadata": {
        "id": "IURIWD4j7OBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_linknet_model(num_classes=1, backbone='resnet34'):\n",
        "    return Linknet(\n",
        "        backbone,\n",
        "        encoder_weights='imagenet',\n",
        "        classes=num_classes,\n",
        "        activation='softmax' if num_classes > 1 else 'sigmoid'\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "DY6rzAeE3IB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_unet_model(num_classes=1, backbone='resnet34'):\n",
        "    return Unet(\n",
        "        backbone,\n",
        "        encoder_weights='imagenet',\n",
        "        classes=num_classes,\n",
        "        activation='softmax' if num_classes > 1 else 'sigmoid'\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "vCflh1cb4HGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitetura proposto por Ulas"
      ],
      "metadata": {
        "id": "MP_30iwQG5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "zYDwVYDzHXos"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.activations import swish\n",
        "from tensorflow.keras.layers import (Activation, AveragePooling2D, BatchNormalization, Conv2D, MaxPooling2D,\n",
        "                                     UpSampling2D, concatenate)\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNa9WsFXHDqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_item_dense_layer(inputs, filters, kernel):\n",
        "    conv = Conv2D(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel,\n",
        "        padding='same',\n",
        "        use_bias=False\n",
        "    )(inputs)\n",
        "    bn = BatchNormalization()(conv)\n",
        "    act = Activation(swish)(bn)\n",
        "\n",
        "    return act"
      ],
      "outputs": [],
      "metadata": {
        "id": "zh84s9GzHl_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def _get_ulas_dense_layer(input, conv_confs):\n",
        "    fst = _get_ulas_item_dense_layer(input, *conv_confs[0])\n",
        "    snd = _get_ulas_item_dense_layer(concatenate([input, fst]), *conv_confs[1])\n",
        "    trd = _get_ulas_item_dense_layer(concatenate([input, fst, snd]), *conv_confs[2])\n",
        "    frt = _get_ulas_item_dense_layer(concatenate([input, fst, snd, trd]), *conv_confs[3])\n",
        "\n",
        "    return frt"
      ],
      "outputs": [],
      "metadata": {
        "id": "rVOVnG5QHoWx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_ulas_model(num_classes=1, pool_size=POOL_SIZE):\n",
        "    input = Input(\n",
        "        shape=(IMG_SZ, IMG_SZ, INPUT_CHANNELS),\n",
        "        dtype='float32'\n",
        "    )\n",
        "\n",
        "    # 1º parte do encoder\n",
        "    dense1 = _get_ulas_dense_layer(\n",
        "        input,\n",
        "        [\n",
        "            (160, (3, 7)),\n",
        "            (112, (3, 7)),\n",
        "            (144, (9, 7)),\n",
        "            (80, (3, 11)),\n",
        "        ]\n",
        "    )\n",
        "    trans1 = MaxPooling2D(pool_size=(pool_size, pool_size))(dense1)\n",
        "\n",
        "    # 2º parte do encoder\n",
        "    dense2 = _get_ulas_dense_layer(\n",
        "        trans1, \n",
        "        [\n",
        "            (144, (3, 5)),\n",
        "            (176, (7, 1)),\n",
        "            (144, (9, 9)),\n",
        "            (96, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "    trans2 = AveragePooling2D(pool_size=(pool_size, pool_size))(dense2)\n",
        "\n",
        "    # 1º parte da ponte\n",
        "    dense3 = _get_ulas_dense_layer(\n",
        "        trans2, \n",
        "        [\n",
        "            (176, (1, 1)),\n",
        "            (128, (3, 5)),\n",
        "            (208, (7, 7)),\n",
        "            (212, (3, 3)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte da ponte\n",
        "    dense4 = _get_ulas_dense_layer(\n",
        "        dense3, \n",
        "        [\n",
        "            (64, (1, 7)),\n",
        "            (208, (3, 5)),\n",
        "            (64, (9, 5)),\n",
        "            (208, (7, 9)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 1º parte do decoder\n",
        "    trans3 = UpSampling2D(size=(pool_size, pool_size))(dense4)\n",
        "    dense5 = _get_ulas_dense_layer(\n",
        "        trans3, \n",
        "        [\n",
        "            (208, (5, 7)),\n",
        "            (64, (3, 5)),\n",
        "            (96, (11, 11)),\n",
        "            (112, (7, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 2º parte do decoder\n",
        "    trans4 = UpSampling2D(size=(pool_size, pool_size))(dense5)\n",
        "    dense6 = _get_ulas_dense_layer(\n",
        "        trans4, \n",
        "        [\n",
        "            (128, (5, 5)),\n",
        "            (80, (11, 7)),\n",
        "            (64, (1, 1)),\n",
        "            (16, (3, 7)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    final = Conv2D(\n",
        "        filters=num_classes,\n",
        "        kernel_size=(3, 7),\n",
        "        padding='same',\n",
        "        activation='softmax'\n",
        "    )(dense6)\n",
        "\n",
        "    model = Model(inputs=input, outputs=final)\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "u4qjBkYZHid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências de Treinamento\n",
        "\n"
      ],
      "metadata": {
        "id": "iIDrnFqqI8yY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "TKGfQssKJOes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from segmentation_models.losses import DiceLoss, CategoricalFocalLoss\n",
        "from segmentation_models.metrics import IOUScore, FScore"
      ],
      "outputs": [],
      "metadata": {
        "id": "3-8d_PzFJQ_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=INIT_LEARNING_RATE\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "9KNRADbkJjxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=AUG_ROTATION,\n",
        "    horizontal_flip=AUG_W_HOR_FLIP,\n",
        "    vertical_flip=AUG_W_VER_FLIP,\n",
        "    width_shift_range=AUG_WIDTH_RNG,\n",
        "    height_shift_range=AUG_HEIGHT_RNG,\n",
        "    zoom_range=AUG_ZOOM,\n",
        "\tfill_mode=AUG_FILL_MODE\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "--5ZhnlqO7fM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def loss_func(class_weights):\n",
        "    dice_loss = DiceLoss(class_weights=class_weights, smooth=SMOOTH)\n",
        "    focal_loss = CategoricalFocalLoss(gamma=FOCAL_LOSS_GAMA)\n",
        "\n",
        "    return dice_loss + focal_loss"
      ],
      "outputs": [],
      "metadata": {
        "id": "bUKz7pdSFM2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def metric_func(class_weights):\n",
        "    return [\n",
        "        dice_metric,\n",
        "        jaccard_metric,\n",
        "        'accuracy',\n",
        "        'categorical_accuracy',\n",
        "        MeanIoU(num_classes=CLASSES_CNT),\n",
        "        IOUScore(class_weights=class_weights, smooth=SMOOTH, threshold=METRIC_THRESHOLD),\n",
        "        FScore(smooth=SMOOTH, threshold=METRIC_THRESHOLD)\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "rHnUtiZKHG9e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def compile_model(model, class_weights=[]):\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        # 'categorical_crossentropy' | 'sparse_categorical_crossentropy'\n",
        "        # https://keras.io/api/losses/probabilistic_losses/\n",
        "        # loss='categorical_crossentropy',\n",
        "        loss=loss_func(class_weights),\n",
        "        # https://keras.io/api/metrics/\n",
        "        metrics=metric_func(class_weights)\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "tFE1qbESJpsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "kXTmW4Fc0RGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epoch_milestone = ModelCheckpoint(\n",
        "    STEPS_FILENAME,\n",
        "    monitor=f'val_{EVAL_METRIC}',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xm2EhKXtLS5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=EARLY_STOP_PATIENCE,\n",
        "    verbose=1,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "p29VDRt5LTvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "csv_logger = CSVLogger(\n",
        "    CSV_LOG_FILENAME,\n",
        "    separator=';',\n",
        "    append=True,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "TNCOR_CDLUwg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lr_reducer = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=LR_REDUCER_PATIENCE,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        "    factor=1e-1,\n",
        "    verbose=1\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "ea-WROIfMSIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "callbacks = [\n",
        "    epoch_milestone,\n",
        "    early_stop,\n",
        "    csv_logger,\n",
        "    lr_reducer,\n",
        "]"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ec8Tejy7NAgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando dados\n",
        "\n"
      ],
      "metadata": {
        "id": "eM2eHxDXYaBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "2vWJJxjQsFHx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_cnt = check_cnt(TRAINING_DIR)\n",
        "train_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27wkIDcPlIvk",
        "outputId": "13fc550d-f80e-4f35-b204-b9612686e9c3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_cnt = check_cnt(X_VAL_DIR)\n",
        "xval_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9dNLmoTnccA",
        "outputId": "95426f30-b577-4697-d241-9bcddc271753"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_cnt = check_cnt(TEST_DIR)\n",
        "test_cnt"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xmGpodMnbjK",
        "outputId": "b7b01e22-714c-4f6a-81fe-0d7caa740334"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "there_are_preload_data = all([train_cnt, test_cnt, xval_cnt])\n",
        "there_are_preload_data"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGw8uGkNoD6m",
        "outputId": "a466b21a-c8a0-433f-eda3-7b8bb2e51824"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedimentos na ausência de dados"
      ],
      "metadata": {
        "id": "ae61zcz2n47-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    training_paths = file_paths(RAW_TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "U97IDRZ4odfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    raw_train_data, raw_train_labels = load_data(training_paths)\n",
        "\n",
        "    print(f'raw_train_data: {raw_train_data.shape}\\n\\t{raw_train_data.dtype}')\n",
        "    print(f'raw_train_labels: {raw_train_labels.shape}\\n\\t{raw_train_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "DdNcrIy3opZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    classes_weight = load_classes_weight(raw_train_labels)\n",
        "else:\n",
        "    classes_weight = load_classes_weight()\n",
        "\n",
        "print(f'classes_weight:\\n{classes_weight}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm2tBF0Zoq9Y",
        "outputId": "4fb5f251-407b-49d7-839c-c7550eae5a5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "        raw_train_data.numpy(), raw_train_labels.numpy(),\n",
        "        test_size=VALIDATION_PROPORTION,\n",
        "        random_state=RANDOM_SEED\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "qrlPUllpotTU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_data, xval_data, train_labels, xval_labels = train_test_split(\n",
        "        train_data, train_labels,\n",
        "        test_size=XVALIDATION_PROPORTION,\n",
        "        random_state=RANDOM_SEED\n",
        "    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "89IGWQwKowno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    print(f'train_data: {train_data.shape} - {train_data.dtype}')\n",
        "    print(f'train_labels: {train_labels.shape} - {train_labels.dtype}')\n",
        "    \n",
        "    print(f'xval_data: {xval_data.shape} - {xval_data.dtype}')\n",
        "    print(f'xval_labels: {xval_labels.shape} - {xval_labels.dtype}')\n",
        "\n",
        "    print(f'test_data: {test_data.shape} - {test_data.dtype}')\n",
        "    print(f'test_labels: {test_labels.shape} - {test_labels.dtype}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "j6K6x0hdoxpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(train_labels, TRAINING_DIR, is_label=True)\n",
        "    save_patches(train_data, TRAINING_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "X6hErjD7oxUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(xval_labels, X_VAL_DIR, is_label=True)\n",
        "    save_patches(xval_data, X_VAL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FXlAJCwI0NfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    save_patches(test_labels, TEST_DIR, is_label=True)\n",
        "    save_patches(test_data, TEST_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6ofGQvPJ0OOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    del training_paths\n",
        "    del train_data\n",
        "    del train_labels\n",
        "    del xval_data\n",
        "    del xval_labels\n",
        "    del test_data\n",
        "    del test_labels"
      ],
      "outputs": [],
      "metadata": {
        "id": "EbamHiCooxAj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "if not there_are_preload_data:\n",
        "    train_cnt = check_cnt(TRAINING_DIR)\n",
        "    train_cnt\n",
        "\n",
        "    xval_cnt = check_cnt(X_VAL_DIR)\n",
        "    xval_cnt\n",
        "\n",
        "    test_cnt = check_cnt(TEST_DIR)\n",
        "    test_cnt"
      ],
      "outputs": [],
      "metadata": {
        "id": "QVzsy8AQCqsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_dataset = get_dataset(TRAINING_DIR, is_allowed_to_shuffle=True)\n",
        "train_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "2XyC1fQoYmpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a2a641-9c55-4858-be41-b3fd8c720e04"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "xval_dataset = get_dataset(X_VAL_DIR)\n",
        "xval_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "C445gwTDJ1Dx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_dataset = get_dataset(TEST_DIR)\n",
        "test_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "6RejhvbCJtzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualização teste"
      ],
      "metadata": {
        "id": "X4Pej9qVUj_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for image, mask in train_dataset.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "    print('min image', tf.math.reduce_min(sample_image[0]))\n",
        "    print('max image', tf.math.reduce_max(sample_image[0]))\n",
        "    print('image', type(sample_image), sample_image.shape)\n",
        "    print('mask', type(sample_mask), sample_mask.shape)\n",
        "\n",
        "display_sample([sample_image[0], sample_mask[0]])"
      ],
      "outputs": [],
      "metadata": {
        "id": "dQo_5QgrwSi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e444a9cf-7fbf-4a40-da07-c48cf79803b2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando model"
      ],
      "metadata": {
        "id": "hRDKvbFVwLL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports da seção"
      ],
      "metadata": {
        "id": "t1LhMMmt-xNT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "outputs": [],
      "metadata": {
        "id": "euPOixtlyVql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "get_model = f'get_{MODEL_FILENAME}'"
      ],
      "outputs": [],
      "metadata": {
        "id": "PGqgBSc_yXWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "clear_session()"
      ],
      "outputs": [],
      "metadata": {
        "id": "HVxPNvJSyZAA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = load_model(MODEL_FILENAME, MODEL_DIR) or eval(get_model)(CLASSES_CNT)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hK-2y3zpyanu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa84575d-82ab-42a3-fdcb-67ce36c53c3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = compile_model(model, classes_weight)"
      ],
      "outputs": [],
      "metadata": {
        "id": "0_26VypCygR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gHZNGULAybLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.summary()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5frUAbo7yinL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f15e27-7324-4d86-90d0-01e2d8d96c0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_model(\n",
        "    model,\n",
        "    to_file=PLOT_FILENAME,\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=True,\n",
        "    dpi=120,\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fRnLBHq0ykSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cac4c5-6e1a-415e-e1c9-1fa91b54588d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização prévia"
      ],
      "metadata": {
        "id": "NHNgrwTVUFzc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "cx1lZwgZUKNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "i_ooPSRWULIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed261618-af08-4aba-8d09-b76a44066c74"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# for image, mask in xval_dataset.take(1):\n",
        "#     sample_image, sample_mask = image, mask\n",
        "\n",
        "# predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "\n",
        "# display_sample([sample_image[0], sample_mask[0], predict_img[0]], to_save=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rhNbEGDgUMTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad5ddfa-8fd3-4d9b-8c17-80c50177d91b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "s1agFI3Xyrws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "STEPS_PER_EPOCH = train_cnt // BATCH_SIZE\n",
        "STEPS_PER_EPOCH"
      ],
      "outputs": [],
      "metadata": {
        "id": "oQSEOwFJBgeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd8770d-5b6a-44ff-ff56-a6ddd6794060"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VALIDATION_STEPS = xval_cnt // BATCH_SIZE\n",
        "VALIDATION_STEPS "
      ],
      "outputs": [],
      "metadata": {
        "id": "-_TczQjUCDyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db52109e-d735-4048-b5d2-4afed83b3b85"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "results = model.fit(\n",
        "    # x=aug.flow(train_data, train_labels, batch_size=BATCH_SIZE, seed=RANDOM_SEED),\n",
        "    train_dataset,\n",
        "    initial_epoch=INITAL_EPOCH,\n",
        "    epochs=MAX_EPOCH,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    # validation_data=(xval_data, xval_labels),\n",
        "    validation_data=xval_dataset,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OLvwUI35y2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3627389-3895-401d-b408-eb89a7285fc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "save_model(model, MODEL_FILENAME, MODEL_DIR)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mMuC0wdQy4W2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(results.history)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QF7moJWny6cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualização final"
      ],
      "metadata": {
        "id": "mZjKdfiev5pT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint"
      ],
      "outputs": [],
      "metadata": {
        "id": "MZGDnqMdwCW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(dpi=180)"
      ],
      "outputs": [],
      "metadata": {
        "id": "60PKi14rwFbp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for image, mask in test_dataset.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "predict_img = tf.convert_to_tensor(model.predict(sample_image))\n",
        "\n",
        "display_sample([sample_image[0], sample_mask[0], predict_img[0]], to_save=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4QKo8VcjwX7y"
      }
    }
  ]
}